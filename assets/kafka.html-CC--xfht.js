import{_ as i}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as l,o as p,c as r,a as e,b as n,d as a,w as t,f as s}from"./app-CoZ3ixxr.js";const u={},d=e("h1",{id:"kafka导航栏",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#kafka导航栏"},[e("span",null,"Kafka导航栏")])],-1),k=e("strong",null,"Topic",-1),h=e("strong",null,"Partition",-1),f=e("strong",null,"Replication",-1),g=e("li",null,[e("p",null,[e("strong",null,"Record"),n(" ： 实际写入 Kafka 中并可以被读取的消息记录。每个 record 包含了 key、value 和 timestamp。")])],-1),_=e("strong",null,"Offset",-1),m=e("li",null,[e("p",null,[e("strong",null,"广播消息"),n("：Kafka 通过 Consumer Group 来实现广播模式消息订阅，即不同 group 下的 consumer 可以重复消费消息，相互不影响，同一个 group 下的 consumer 构成一个整体。")])],-1),b=e("li",null,[e("p",null,"消费者组")],-1),K=e("p",null,"❓kafka的 副本的作用 是什么",-1),v=e("p",null,"那么为什么follower副本不对外提供服务？——这个问题本质上是优先保证数据的一致性。",-1),R=e("p",null,"❓Kafka 的多分区机制有什么好处",-1),y=s('<h2 id="kafka文件的存储形式" tabindex="-1"><a class="header-anchor" href="#kafka文件的存储形式"><span>kafka文件的存储形式</span></a></h2><p>Kafka 消息是以 Topic 为单位进行归类，各个 Topic 之间是彼此独立的，互不影响。</p><p>每个 Topic 又可以分为一个或多个分区。每个分区各自存在一个记录消息数据的日志文件。</p><p>Kafka 每个分区日志在物理上实际按大小被分成多个 Segment；目的是为了防止log文件过大导致数据<strong>定位效率低下</strong>，采取<strong>分片</strong>和<strong>索引</strong>的机制。</p><figure><img src="http://images.xyzzs.top/image/image-20230221131242940.png_char_char" alt="image-20230221131242940" tabindex="0" loading="lazy"><figcaption>image-20230221131242940</figcaption></figure><p>一个 Segment 默认大小为 <code>1G</code>， 主要包含以下文件：</p>',6),B=e("li",null,[e("code",null,".log"),n("文件：实实在在存储数据的文件")],-1),x=e("code",null,".index",-1),P=e("code",null,"log.index.interval.bytes",-1),C=e("li",null,[n("保存的"),e("code",null,"offset"),n("为相对的"),e("code",null,"offset"),n("，确保"),e("code",null,"offset"),n("值所占空间不会过大；绝对"),e("code",null,"offse"),n("会越来越大。")],-1),q=e("li",null,[e("code",null,".timeindex"),n("时间戳索引文件：用于"),e("code",null,"删除机制"),n("。")],-1),z=e("li",null,"其他文件",-1),S=s('<blockquote><p>以当前segment的第一条消息的offset命名。</p></blockquote><blockquote><p><strong>稠密索引</strong>： 在密集索引中，数据库中的<strong>每个搜索键值都有一个索引记录</strong>。这样可以加快搜索速度，但需要更多空间来存储索引记录本身。索引记录包含搜索键值和指向磁盘上实际记录的指针。</p><p><strong>稀疏索引</strong>： 在稀疏索引中，<strong>不会为每个搜索关键字创建索引记录</strong>。此处的索引记录包含搜索键和指向磁盘上数据的实际指针。要搜索记录，我们首先按索引记录进行操作，然后到达数据的实际位置。如果我们要寻找的数据不是我们通过遵循索引直接到达的位置，那么系统将开始顺序搜索，直到找到所需的数据为止。</p></blockquote><h2 id="文件清除策略" tabindex="-1"><a class="header-anchor" href="#文件清除策略"><span>文件清除策略</span></a></h2>',3),L=e("ul",null,[e("li",null,[e("code",null,"log.retention.hours"),n("：最低优先级小时，默认168小时（7天）。")]),e("li",null,[e("code",null,"log.retention.minutes"),n("：分钟。")]),e("li",null,[e("code",null,"log.retention.ms"),n("：最高优先级毫秒。")]),e("li",null,[e("code",null,"log.retention.check.interval.ms"),n("：设置检查周期，默认 5 分钟。")])],-1),I=e("p",null,"那么日志超过了设置的时间，怎么处理呢？",-1),T=s('<ol><li><p>启用删除策略：<code>log.cleanup.policy</code> = delete</p><ul><li>基于时间:默认打开。以 segment 中所有记录中的最大时间戳作为该文件时间戳。</li><li>基于大小:默认关闭。超过设置的所有日志总大小，删除最早的 segment。<code>log.retention.bytes</code>，默认等于-1，表示无穷大。</li></ul></li><li><p>启用压缩策略：<code>log.cleanup.policy</code> = compact</p><p>对于相同key的 不同value值，只保留最后一个版本。</p></li></ol><h2 id="kafka为什么快" tabindex="-1"><a class="header-anchor" href="#kafka为什么快"><span>kafka为什么快？</span></a></h2>',2),w=e("li",null,[e("p",null,[e("mark",null,"顺序写磁盘"),n("：以追加的形式到文件末端，节省了大量磁头寻址的过程")])],-1),Z=e("li",null,[e("p",null,[e("mark",null,"零拷贝"),n("：在broker端不需要对数据进行任何，直接发往网卡，所有处理可放在生产端或者消费端进行；减少了系统调用，避免在 "),e("code",null,"用户态(User-space)"),n(" 与 "),e("code",null,"内核态(Kernel-space)"),n(" 之间来回拷贝数据。")])],-1),A=e("p",null,[e("mark",null,"页缓存"),n("：")],-1),F=e("ul",null,[e("li",null,[n("producer 生产消息到 Broker 时，Broker 会使用 pwrite() 系统调用【对应到 Java NIO 的 FileChannel.write() API】按偏移量写入数据，数据都会先写入"),e("code",null,"page cache"),n("。")]),e("li",null,"consumer 消费消息时，Broker 使用 sendfile() 系统调用【对应 FileChannel.transferTo() API】，零拷贝地将数据从 page cache 传输到 broker 的 Socket buffer，再通过网络传输。")],-1),j=e("blockquote",null,[e("p",null,"leader 与 follower 之间的同步，与上面 consumer 消费数据的过程是同理的。")],-1),N=e("code",null,"page cache",-1),E=e("code",null,"page cache",-1),M=e("li",null,[e("p",null,[e("mark",null,"网络模型"),n("：底层基于 Java NIO，采用和 Netty 一样的 Reactor 线程模型。")])],-1),O=e("p",null,[e("mark",null,"批量传输与压缩消息")],-1),G=e("p",null,[e("code",null,"Producer"),n(" 有两个重要的参数：和 "),e("code",null,"Producer"),n(" 的批量发送消息有关。")],-1),U=e("ul",null,[e("li",null,[e("code",null,"batch.size"),n("：16KB")]),e("li",null,"``linger.ms`：默认0ms，表示没有延迟。")],-1),V=e("p",null,"主要是为了让传输消息的次数变得更少，压缩主要是为了降低网络传输的消耗，提高吞吐量。",-1),W=e("code",null,"Broker",-1),J=e("code",null,"Broker",-1),D=e("code",null,"Producer",-1),H=e("code",null,"Consumer",-1),Q=e("code",null,"Consumer",-1),X=e("code",null,"Consumer",-1),Y=e("p",null,[e("mark",null,"分区并发"),n("：本身就是分布式集群，可以采用分区技术，并行度高")],-1),$=e("ol",null,[e("li",null,"需要更多的资源"),e("li",null,"降低高可用性：分区越多，每个 Broker 上分配的分区也就越多，当一个发生 Broker 宕机，那么恢复时间将很长。")],-1),ee=e("p",null,[e("mark",null,"文件结构"),n("：")],-1),ne=e("li",null,"Kafka 充分利用二分法来查找对应 offset 的消息位置：",-1),ae=s(`<h2 id="如何保证kafka不丢失消息" tabindex="-1"><a class="header-anchor" href="#如何保证kafka不丢失消息"><span>⭐如何保证Kafka不丢失消息?</span></a></h2><p><mark>生产者丢失消息的情况</mark></p><p><code>Producer</code> 使用 <code>send()</code> 方法发送消息是异步的操作，我们可以通过 <code>get()</code>方法获取调用结果，但是这样也让它变为了同步操作，示例代码如下：</p><div class="language-java line-numbers-mode" data-ext="java" data-title="java"><pre class="language-java"><code><span class="token class-name">SendResult</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Object</span><span class="token punctuation">&gt;</span></span> sendResult <span class="token operator">=</span> kafkaTemplate<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>topic<span class="token punctuation">,</span> o<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span>sendResult<span class="token punctuation">.</span><span class="token function">getRecordMetadata</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
  logger<span class="token punctuation">.</span><span class="token function">info</span><span class="token punctuation">(</span><span class="token string">&quot;生产者成功发送消息到&quot;</span> <span class="token operator">+</span> sendResult<span class="token punctuation">.</span><span class="token function">getProducerRecord</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">topic</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot;-&gt; &quot;</span> <span class="token operator">+</span> sendRe
              sult<span class="token punctuation">.</span><span class="token function">getProducerRecord</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,4),oe=s(`<div class="language-java line-numbers-mode" data-ext="java" data-title="java"><pre class="language-java"><code><span class="token class-name">ListenableFuture</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">SendResult</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Object</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> future <span class="token operator">=</span> kafkaTemplate<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>topic<span class="token punctuation">,</span> o<span class="token punctuation">)</span><span class="token punctuation">;</span>
future<span class="token punctuation">.</span><span class="token function">addCallback</span><span class="token punctuation">(</span>result <span class="token operator">-&gt;</span> logger<span class="token punctuation">.</span><span class="token function">info</span><span class="token punctuation">(</span><span class="token string">&quot;生产者成功发送消息到topic:{} partition:{}的消息&quot;</span><span class="token punctuation">,</span> result<span class="token punctuation">.</span><span class="token function">getRecordMetadata</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">topic</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> result<span class="token punctuation">.</span><span class="token function">getRecordMetadata</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">partition</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                ex <span class="token operator">-&gt;</span> logger<span class="token punctuation">.</span><span class="token function">error</span><span class="token punctuation">(</span><span class="token string">&quot;生产者发送消失败，原因：{}&quot;</span><span class="token punctuation">,</span> ex<span class="token punctuation">.</span><span class="token function">getMessage</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>另外，建议根据实际情况设置以下参数：</p>`,2),te=e("code",null,"retries",-1),se=e("code",null,"retry.backoff.ms",-1),le={href:"https://so.csdn.net/so/search?q=%E5%9B%9E%E8%B0%83&spm=1001.2101.3001.7020",target:"_blank",rel:"noopener noreferrer"},ce=s("<p><mark>消费者丢失消息的情况</mark></p><p>当消费者拉取到了分区的某个消息之后，消费者默认会自动提交 <code>offset</code>。</p><p>我们手动关闭自动提交 <code>offset</code>，每次在真正消费完消息之后之后再自己手动提交 <code>offset</code> 。但是，细心的朋友一定会发现，这样会带来消息被重新消费的问题。比如你刚刚消费完消息之后，还没提交 <code>offset</code>，结果自己挂掉了，那么这个消息理论上就会被消费两次，所以手动提交消息需要做一些幂等性的措施。</p><ul><li>同步提交</li><li>异步提交</li></ul><p><mark>Broker 弄丢了消息</mark></p>",5),ie=s("<li><p>设置 <code>acks</code> = all</p><ul><li>-1(all)：表示只有所有 ISR 列表的副本全部收到消息时，生产者才会接收到来自服务器的响应. 这种模式是最高级别的，也是最安全的，该模式的延迟会很高.</li><li>1：也是默认值，代表我们的消息被leader副本接收之后就算被成功发送。</li><li>0：立马响应返回，异步</li></ul><p>若配置为<code>all</code>，如果有一台 Follower 宕机，那么会永远无法ack</p></li><li><p>设置 <code>replication.factor</code> ：分区副本大于等于2，保证即使分区的<code>leader</code>挂掉，其他<code>follower</code>被选中为leader也会正常处理消息。</p></li><li><p>设置 <code>min.insync.replicas</code> ：ISR 里应答的最小副本数量大于等于2，原理同上，也需要大于 1 的副本数量来保证消息不丢失。</p><blockquote><p>确保 replication.factor &gt; min.insync.replicas</p><p>如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成。推荐设置成 replication.factor = min.insync.replicas + 1。</p></blockquote></li>",3),pe=e("p",null,"设置 unclean.leader.election.enable = false",-1),re=s("<p>发送的消息会被发送到 <code>Leader</code> 副本，然后 <code>Follower</code> 副本才能从 <code>Leader</code> 副本中拉取消息进行同步。多个 <code>Follower</code> 副本之间的消息同步情况不一样，当我们配置了 <code>unclean.leader.election.enable = false</code> 的话，当 <code>Leader</code> 副本发生故障时就不会从 <code>Follower</code> 副本中和 <code>Leader</code> 同步程度达不到要求的副本中选择出 <code>Leader</code> ，这样降低了消息丢失的可能性。</p><blockquote><p>Kafka 0.11.0.0 版本开始 unclean.leader.election.enable 参数的默认值由原来的 true 改为 false</p></blockquote>",2),ue=s('<blockquote><p>精确一次：幂等性和事务</p></blockquote><h2 id="kafka-如何保证消息的消费顺序" tabindex="-1"><a class="header-anchor" href="#kafka-如何保证消息的消费顺序"><span>Kafka 如何保证消息的消费顺序？</span></a></h2><ol><li>一个 Topic 只对应一个 Partition。</li><li>（推荐）发送消息的时候指定 key/Partition。</li></ol><p>如何保证生产端单分区有序呢？</p><ul><li><p>kafka在1.x版本之前保证数据单分区有序，条件如下:</p><p><code>max.in.flight.requests.perconnection</code>=1 (不需要考虑是否开启幂等性)</p></li><li><p>kafka在1.x及以后版本保证数据单分区有序，条件如下:</p><ol><li><p>未开启幂等性：max.in.fight.requests.perconnection黑要设置为1。</p></li><li><p>开启幂等性：max.in.flight.requests.per.connection需要设置小于等于5</p><p>原因说明：因为在kafkal,x以后，启用幂等后，kafka服务端会缓存producer发来的最近5个request的元数据，故无论如何，都可以保证最近5个request的数据都是有序的。</p></li></ol></li></ul><blockquote><p>单分区有序，可能会造成数据倾斜；想要实现多分区有序，需在消费端排序。</p></blockquote><h2 id="分区策略" tabindex="-1"><a class="header-anchor" href="#分区策略"><span>分区策略</span></a></h2><p>即生产者发往 Broker 时，采用何种策略</p><p>同一个 Topic 可以创建多个分区。理论上分区越多并发度越高，Kafka 会<strong>根据分区策略将分区尽可能均衡的分布在不同的 Broker 节点上，以避免消息倾斜</strong>，不同的 Broker 负载差异太大。分区也不是越多越好哦，毕竟太多邮政公司也管理不过来。</p><ol><li>若指定 partition，则按照 partition 发往指定的分区</li><li>若未指定 partition ，但选择了 key，则按照 key 的哈希值取模后发往指定分区</li><li>会随机选择一个分区，待batch满后或已完成， 再随机选一个（和上一次分区不同）——3.0版本</li></ol><blockquote><p>自定义分区器：实现Partitioner接口，重写partition()方法</p></blockquote><h2 id="kafka消费组-分区分配策略及重平衡机制" tabindex="-1"><a class="header-anchor" href="#kafka消费组-分区分配策略及重平衡机制"><span>Kafka消费组 分区分配策略及重平衡机制</span></a></h2><p>首先：一个消费者组中的消费者只能消费一个分区！</p><figure><img src="http://images.xyzzs.top/image/1677028966704-9b5a4f2e-abfe-45b5-9dca-575157a6c096.png_char" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>分区分配策略：<code>partition.assignment.strategy</code>，默认的赋值器是[ RangeAssignor , CooperativeStickyAssignor ]。</p><p>实现<code>org.apache.kafka.clients.consumer.ConsumerPartitionAssignor</code>接口允许插入一个自定义分配策略。</p><ul><li><p>Range</p><p>首先对<strong>同一个 topic</strong> 的分区按序号进行排序，并对消费者按照字母顺序进行排序；</p><p>然后通过 partition数 / consumer数来决定每个消费者应该消费几个分区。如果除不尽，前面的几个消费者将会多消费 1 个分区</p><blockquote><p>topic个数比较多时，容易产生数据倾斜</p></blockquote></li><li><p>RoundRobin：针对集群中<strong>所有 topic</strong> ，把所有 partition 和所有的 consumer 都列出来，然后按照 hashCode进行排序，最好通过轮询算法来分配 partition 给到各个消费者。</p></li><li><p>StickyAssignor：黏性，类似Range，有一定随机性</p></li><li><p>CooperativeStickyAssignor：合作者黏性</p></li></ul><p><strong>假如某个 Consumer Group 突然加入或者退出了一个 Consumer，会发生什么情况呢？</strong></p><p>会触发 <strong>重平衡</strong> ，它本质上是一种协议，规定了一个 Consumer Group 下的所有 Consumer 如何达成一致来分配订阅 Topic 的每个分区。</p><h2 id="zookeeper-存储" tabindex="-1"><a class="header-anchor" href="#zookeeper-存储"><span>zookeeper 存储</span></a></h2><p>ZooKeeper 主要为 Kafka 提供元数据的管理的功能。</p><figure><img src="http://images.xyzzs.top/image/1677032584417-2a5caeeb-d674-4f31-9760-2d728390a041.png_char" alt="image.png" tabindex="0" loading="lazy"><figcaption>image.png</figcaption></figure><ul><li>Kafka Controller 的 Leader 选举</li><li>Kafka 集群成员管理</li><li>Topic 配置管理</li><li>分区副本管理</li></ul><p>Zookeeper 主要为 Kafka 做了下面这些事情：</p><ol><li><strong>Broker 注册</strong> ：在 Zookeeper 上会有一个专门<strong>用来进行 Broker 服务器列表记录</strong>的节点。每个 Broker 在启动时，都会到 Zookeeper 上进行注册，即到/brokers/ids 下创建属于自己的节点。每个 Broker 就会将自己的 IP 地址和端口等信息记录到该节点中去</li><li><strong>Topic 注册</strong> ： 在 Kafka 中，同一个<strong>Topic 的消息会被分成多个分区</strong>并将其分布在多个 Broker 上，<strong>这些分区信息及与 Broker 的对应关系</strong>也都是由 Zookeeper 在维护。比如我创建了一个名字为 my-topic 的主题并且它有两个分区，对应到 zookeeper 中会创建这些文件夹：<code>/brokers/topics/my-topic/Partitions/0</code>、<code>/brokers/topics/my-topic/Partitions/1</code></li><li><strong>负载均衡</strong> ： Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力。 对于同一个 Topic 的不同 Partition，Kafka 会尽力将这些 Partition 分布到不同的 Broker 服务器上。当生产者产生消息后也会尽量投递到不同 Broker 的 Partition 里面。当 Consumer 消费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数量来实现动态负载均衡。</li><li>等等。。。。</li></ol><blockquote><p>2.8版本后，采用 Kraft模式，不再依赖 zk ，但此版本还可以兼容 zk。</p></blockquote><h2 id="高可用" tabindex="-1"><a class="header-anchor" href="#高可用"><span>高可用</span></a></h2><h3 id="备份机制" tabindex="-1"><a class="header-anchor" href="#备份机制"><span>备份机制</span></a></h3><p>Kafka 允许同一个 Partition 存在多个消息副本，每个 Partition 的副本通常由 1 个 Leader 及 0 个以上的 Follower 组成，生产者将消息直接发往对应 Partition 的 Leader，Follower 会周期地向 Leader 发送同步请求</p>',29),de=e("p",null,"所以 Kafka 会尽量将所有的 Partition 以及各 Partition 的副本均匀地分配到整个集群的各个 Broker 上",-1),ke=e("h3",{id:"isr-机制",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#isr-机制"},[e("span",null,"ISR 机制")])],-1),he=e("p",null,[e("mark",null,"ISR 副本集合")],-1),fe=e("p",null,"ISR 中的副本都是与 Leader 同步的副本，相反，不在 ISR 中的追随者副本就被认为是与 Leader 不同步的",-1),ge=e("code",null,"replica.lag.time.max.ms",-1),_e=e("code",null,"replica.fetch.wait.max.ms",-1),me=e("p",null,"各 Partition 的 Leader 负责维护 ISR 列表并将 ISR 的变更同步至 ZooKeeper，被移出 ISR 的 Follower 会继续向 Leader 发 FetchRequest 请求，试图再次跟上 Leader 重新进入 ISR",-1),be=e("p",null,[e("mark",null,"Unclean 领导者选举")],-1),Ke=e("p",null,[n("当 Kafka 中"),e("code",null,"unclean.leader.election.enable"),n("配置为 true(默认值为 false)。在 ISR 中所有副本均宕机的情况下，才被允许 ISR 外的副本被选为 Leader，此时会丢失部分已应答的数据")],-1),ve=s('<h3 id="ack-机制" tabindex="-1"><a class="header-anchor" href="#ack-机制"><span>ACK 机制</span></a></h3><ul><li><strong>「acks=0」</strong></li></ul><p>生产者无需等待服务端的任何确认，消息被添加到生产者套接字缓冲区后就视为已发送，因此 acks=0 不能保证服务端已收到消息</p><ul><li><strong>「acks=1」</strong></li></ul><p>只要 <code>Partition Leader</code> 接收到消息而且写入本地磁盘了，就认为成功了，不管它其他的 Follower 有没有同步过去这条消息了</p><ul><li><strong>「acks=all (-1) 」</strong></li></ul><p>Leader 将等待 ISR 中的所有副本确认后再做出应答，因此只要 ISR 中任何一个副本还存活着，这条应答过的消息就不会丢失</p>',7),Re=s('<p>Broker 有个配置项<code>min.insync.replicas</code>(默认值为 1)代表了正常写入生产者数据所需要的最少 ISR 个数</p><p>当 ISR 中的副本数量小于<code>min.insync.replicas</code>时，Leader 停止写入生产者生产的消息，并向生产者抛出 NotEnoughReplicas 异常，阻塞等待更多的 Follower 赶上并重新进入 ISR</p><p>被 Leader 应答的消息都至少有<code>min.insync.replicas</code>个副本，因此能够容忍<code>min.insync.replicas-1</code>个副本同时宕机</p><h3 id="故障恢复机制" tabindex="-1"><a class="header-anchor" href="#故障恢复机制"><span>故障恢复机制</span></a></h3><p>首先需要在集群所有 Broker 中选出一个 Controller，负责各 Partition 的 Leader 选举以及 Replica 的重新分配</p><p>当出现 Leader 故障后，Controller 会将 Leader/Follower 的变动通知到需为此作出响应的 Broker。</p><p>Kafka 使用 ZooKeeper 存储 Broker、Topic 等状态数据，Kafka 集群中的 Controller 和 Broker 会在 ZooKeeper 指定节点上注册 Watcher(事件监听器)，以便在特定事件触发时，由 ZooKeeper 将事件通知到对应 Broker</p><p><mark>Broker 故障恢复流程</mark></p><p><strong>「当 Broker 发生故障后，由 Controller 负责选举受影响 Partition 的新 Leader 并通知到相关 Broker」</strong></p><ul><li>当 Broker 出现故障与 ZooKeeper 断开连接后，该 Broker 在 ZooKeeper 对应的 znode 会自动被删除，ZooKeeper 会触发 Controller 注册在该节点的 Watcher；</li><li>Controller 从 ZooKeeper 的<code>/brokers/ids</code>节点上获取宕机 Broker 上的所有 Partition；</li><li>Controller 再从 ZooKeeper 的<code>/brokers/topics</code>获取所有 Partition 当前的 ISR；</li><li>对于宕机 Broker 是 Leader 的 Partition，Controller 从 ISR 中选择幸存的 Broker 作为新 Leader；</li><li>最后 Controller 通过 LeaderAndIsrRequest 请求向的 Broker 发送 LeaderAndISRRequest 请求。</li></ul><p><mark>Controller 故障恢复流程</mark></p><p>集群中的 Controller 也会出现故障，因此 Kafka 让所有 Broker 都在 ZooKeeper 的 Controller 节点上注册一个 Watcher</p><p>Controller 发生故障时对应的 Controller 临时节点会自动删除，此时注册在其上的 Watcher 会被触发，所有活着的 Broker 都会去竞选成为新的 Controller(即创建新的 Controller 节点，由 ZooKeeper 保证只会有一个创建成功)</p><p>竞选成功者即为新的 Controller。</p><h2 id="选举" tabindex="-1"><a class="header-anchor" href="#选举"><span>选举</span></a></h2>',15),ye=e("figure",null,[e("img",{src:"http://images.xyzzs.top/image/1677033107884-909b1a15-04d7-4fff-9740-517fec12bd8c.png_char",alt:"image.png",tabindex:"0",loading:"lazy"}),e("figcaption",null,"image.png")],-1),Be=e("p",null,"宕机后恢复，会打乱 ISR 顺序",-1),xe=e("p",null,"压测结果",-1);function Pe(Ce,qe){const o=l("font"),c=l("ExternalLinkIcon");return p(),r("div",null,[d,e("ul",null,[e("li",null,[e("p",null,[k,n(" 是一个消息的"),a(o,{color:"orchid"},{default:t(()=>[n("逻辑")]),_:1}),n("分类，只是一个逻辑概念，代表了一类消息。通常我们可以使用 topic 来区分实际业务，比如业务 A 使用一个 topic，业务 B 使用另外一个 topic 。")])]),e("li",null,[e("p",null,[h,n(" 是"),a(o,{color:"orchid"},{default:t(()=>[n("物理")]),_:1}),n("的概念，就是物理上进行分离，分布在不同的实体机器（broke）上。")])]),e("li",null,[e("p",null,[f,n(" ： 副本，是 Kafka "),a(o,{color:"orchid"},{default:t(()=>[n("保证数据高可用的方式")]),_:1}),n("，Kafka 同一 Partition 的数据可以在多 Broker 上存在多个副本，通常"),a(o,{color:"orchid"},{default:t(()=>[n("只有主副本对外提供读写服务")]),_:1}),n("，当主副本所在 broker 崩溃或发生网络异常，Kafka 会在 Controller 的管理下会重新选择新的 Leader 副本对外提供读写服务。")])]),g,e("li",null,[e("p",null,[_,n(" ： offset 是消息在分区中的唯一标识，Kafka 通过它来"),a(o,{color:"orchid"},{default:t(()=>[n("保证消息在分区内的顺序性")]),_:1}),n("，不过 offset 并不跨越分区，也就是说，Kafka 保证的是分区有序性而不是主题有序性。通俗的理解："),a(o,{color:"orchid"},{default:t(()=>[n("单分区内，消费到哪儿了")]),_:1}),n("。新版本保存在 Broker，老版本在zk中。")])]),m,b]),K,e("p",null,[n("在kafka中，实现副本的目的就是冗余备份，"),a(o,{color:"orchid"},{default:t(()=>[n("且仅仅是冗余备份")]),_:1}),n("，所有的读写请求都是由leader副本进行处理的。follower副本仅有一个功能，那就是从leader副本拉取消息，尽量让自己跟leader副本的内容一致。")]),e("p",null,[n("生产者和消费者只与 leader 副本交互。可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了"),a(o,{color:"orchid"},{default:t(()=>[n("提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间")]),_:1}),n("。")]),v,R,e("p",null,[n("给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上，"),a(o,{color:"orchid"},{default:t(()=>[n("可以提高并发能力（负载均衡）")]),_:1}),n("。")]),y,e("ul",null,[B,e("li",null,[x,n("偏移量索引文件：快速定位； "),e("ul",null,[e("li",null,[a(o,{color:"orchid"},{default:t(()=>[n("index为稀疏索引，大约每写入4KB，增加一条索引")]),_:1}),n("。"),P,n("默认4KB。")]),C])]),q,z]),S,a(o,{color:"orchid"},{default:t(()=>[n("默认的保存时间为 7天")]),_:1}),n("，可以通过调整如下参数修改保存时间。"),L,I,e("p",null,[n("Kafka 中提供的日志清理策略有"),a(o,{color:"orchid"},{default:t(()=>[n(" delete（删除） 和 compact（压缩）")]),_:1}),n(" 两种。")]),T,e("ol",null,[w,Z,e("li",null,[A,F,j,e("p",null,[N,n("中的数据会随着内核中 flusher 线程的调度以及对 sync()/fsync() 的调用写回到磁盘，就算进程崩溃，也不用担心数据丢失。另外，如果 "),a(o,{color:"orchid"},{default:t(()=>[n("consumer 要消费的消息不在"),E,n("里，才会去磁盘读取")]),_:1}),n("，并且会顺便预读出一些相邻的块放入 page cache，以方便下一次读取。")]),e("p",null,[n("因此如果 Kafka "),a(o,{color:"orchid"},{default:t(()=>[n("producer 的生产速率与 consumer 的消费速率相差不大")]),_:1}),n("，那么就能几乎只靠对 broker page cache 的读写完成整个生产 - 消费过程，磁盘访问非常少。")])]),M,e("li",null,[O,G,U,V,e("p",null,[W,n(" 接收到压缩后的消息块之后（建议 "),J,n(" 的压缩算法和 "),D,n(" 一样），会依次将压缩后的消息块写入文件中（注意：这个时候消息块 "),a(o,{color:"orchid"},{default:t(()=>[n("还是压缩的状态")]),_:1}),n("），"),H,n(" 同时会依次获取消息块，当消息块到达 "),Q,n(" 后，"),X,n(" 才会对消息块进行解压缩（有压缩必然有解压缩）。")])]),e("li",null,[Y,e("p",null,[n("Kafka 的 Topic 可以分成多个 Partition，每个 Paritition 类似于一个队列，保证数据有序。同一个 Group 下的不同 Consumer 并发消费 Paritition，分区实际上是调优 Kafka 并行度的最小单元，因此，可以说， "),a(o,{color:"orchid"},{default:t(()=>[n("每增加一个 Paritition 就增加了一个消费并发")]),_:1}),n("。")]),a(o,{color:"orchid"},{default:t(()=>[n("但也不是越多越好")]),_:1}),n("："),$]),e("li",null,[ee,e("ul",null,[e("li",null,[n("读数据采用"),a(o,{color:"orchid"},{default:t(()=>[n("稀疏索引")]),_:1}),n("，可以快速定位要消费的数据")]),ne])])]),ae,e("p",null,[n("但是一般不推荐这么做！可以"),a(o,{color:"orchid"},{default:t(()=>[n("采用为其添加回调函数")]),_:1}),n("的形式，示例代码如下：")]),oe,e("p",null,[n("参数 "),te,n(" 表示生产者生产消息的"),a(o,{color:"orchid"},{default:t(()=>[n("重试次数")]),_:1}),n("，可根据实际情况调整。")]),e("p",null,[n("参数"),se,n(" 表示"),a(o,{color:"orchid"},{default:t(()=>[n("重试的时间间隔")]),_:1}),n("，单位是毫秒，如果配置的时间间隔太短，服务可能仍然处于不可用状态。")]),e("p",null,[n("如果重试次数用光后，还是消息发送失败，那么kafka会将异常信息通过"),e("a",le,[n("回调"),a(c)]),n("的形式带给我们，这时，我们可以将没有发送成功的消息进行持久化，做后续的补偿处理。")]),ce,a(o,{color:"orchid"},{default:t(()=>[n("ACK级别设置为all + 分区副本大于等于2 + ISR里应答的最小副本数量大于等于2")]),_:1}),e("ol",null,[ie,e("li",null,[pe,a(o,{color:"orchid"},{default:t(()=>[n("是否启用不在ISR集中的副本作为最后手段被选为leader，这样做可能导致数据丢失")]),_:1}),re])]),ue,a(o,{color:"orchid"},{default:t(()=>[n("同一 Partition 的 Replica 不应存储在同一个 Broker 上")]),_:1}),n("，因为一旦该 Broker 宕机，对应 Partition 的所有 Replica 都无法工作，这就达不到高可用的效果"),de,ke,he,fe,e("p",null,[n("这里的保持同步不是指与 Leader 数据保持完全一致，只需在"),ge,a(o,{color:"orchid"},{default:t(()=>[n("时间内与 Leader 保持有效连接")]),_:1}),n("。Follower 周期性地向 Leader 发送 FetchRequest 请求，发送时间间隔配置在"),_e,n("中，默认值为 500")]),me,be,Ke,e("p",null,[n("开启 Unclean 领导者选举可能会造成数据丢失，但好处是，它"),a(o,{color:"orchid"},{default:t(()=>[n("使得分区 Leader 一直存在，不至于停止对外提供服务")]),_:1}),n("，因此提升了高可用性，反之，禁止 Unclean 领导者选举的好处在于维护了数据的一致性，避免了消息丢失，但牺牲了高可用性")]),ve,e("p",null,[n("acks=all 是可用性最高的选择，但等待 Follower 应答引入了额外的响应时间。Leader 需要等待 ISR 中所有副本做出应答，此时"),a(o,{color:"orchid"},{default:t(()=>[n("响应时间取决于 ISR 中最慢的")]),_:1}),n("那台机器")]),Re,a(o,{color:"orchid"},{default:t(()=>[n("在 ISR 中存活为前提，按照AR中排在签名的优先。")]),_:1}),ye,Be,xe])}const Le=i(u,[["render",Pe],["__file","kafka.html.vue"]]),Ie=JSON.parse('{"path":"/message-queue/kafka.html","title":"Kafka导航栏","lang":"zh-CN","frontmatter":{"description":"Kafka导航栏 Topic 是一个消息的分类，只是一个逻辑概念，代表了一类消息。通常我们可以使用 topic 来区分实际业务，比如业务 A 使用一个 topic，业务 B 使用另外一个 topic 。 Partition 是的概念，就是物理上进行分离，分布在不同的实体机器（broke）上。 Replication ： 副本，是 Kafka ，Kafk...","head":[["meta",{"property":"og:url","content":"https://vuepress-theme-hope-docs-demo.netlify.app/message-queue/kafka.html"}],["meta",{"property":"og:site_name","content":"文档演示"}],["meta",{"property":"og:title","content":"Kafka导航栏"}],["meta",{"property":"og:description","content":"Kafka导航栏 Topic 是一个消息的分类，只是一个逻辑概念，代表了一类消息。通常我们可以使用 topic 来区分实际业务，比如业务 A 使用一个 topic，业务 B 使用另外一个 topic 。 Partition 是的概念，就是物理上进行分离，分布在不同的实体机器（broke）上。 Replication ： 副本，是 Kafka ，Kafk..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"http://images.xyzzs.top/image/image-20230221131242940.png_char_char"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-04-24T15:46:57.000Z"}],["meta",{"property":"article:author","content":"Mr.Hope"}],["meta",{"property":"article:modified_time","content":"2024-04-24T15:46:57.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Kafka导航栏\\",\\"image\\":[\\"http://images.xyzzs.top/image/image-20230221131242940.png_char_char\\",\\"http://images.xyzzs.top/image/1677028966704-9b5a4f2e-abfe-45b5-9dca-575157a6c096.png_char\\",\\"http://images.xyzzs.top/image/1677032584417-2a5caeeb-d674-4f31-9760-2d728390a041.png_char\\",\\"http://images.xyzzs.top/image/1677033107884-909b1a15-04d7-4fff-9740-517fec12bd8c.png_char\\"],\\"dateModified\\":\\"2024-04-24T15:46:57.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Mr.Hope\\",\\"url\\":\\"https://mister-hope.com\\"}]}"]]},"headers":[{"level":2,"title":"kafka文件的存储形式","slug":"kafka文件的存储形式","link":"#kafka文件的存储形式","children":[]},{"level":2,"title":"文件清除策略","slug":"文件清除策略","link":"#文件清除策略","children":[]},{"level":2,"title":"kafka为什么快？","slug":"kafka为什么快","link":"#kafka为什么快","children":[]},{"level":2,"title":"⭐如何保证Kafka不丢失消息?","slug":"如何保证kafka不丢失消息","link":"#如何保证kafka不丢失消息","children":[]},{"level":2,"title":"Kafka 如何保证消息的消费顺序？","slug":"kafka-如何保证消息的消费顺序","link":"#kafka-如何保证消息的消费顺序","children":[]},{"level":2,"title":"分区策略","slug":"分区策略","link":"#分区策略","children":[]},{"level":2,"title":"Kafka消费组 分区分配策略及重平衡机制","slug":"kafka消费组-分区分配策略及重平衡机制","link":"#kafka消费组-分区分配策略及重平衡机制","children":[]},{"level":2,"title":"zookeeper 存储","slug":"zookeeper-存储","link":"#zookeeper-存储","children":[]},{"level":2,"title":"高可用","slug":"高可用","link":"#高可用","children":[{"level":3,"title":"备份机制","slug":"备份机制","link":"#备份机制","children":[]},{"level":3,"title":"ISR 机制","slug":"isr-机制","link":"#isr-机制","children":[]},{"level":3,"title":"ACK 机制","slug":"ack-机制","link":"#ack-机制","children":[]},{"level":3,"title":"故障恢复机制","slug":"故障恢复机制","link":"#故障恢复机制","children":[]}]},{"level":2,"title":"选举","slug":"选举","link":"#选举","children":[]}],"git":{"createdTime":1713973617000,"updatedTime":1713973617000,"contributors":[{"name":"jossezs","email":"zzss5224@163.com","commits":1}]},"readingTime":{"minutes":18.45,"words":5534},"filePathRelative":"message-queue/kafka.md","localizedDate":"2024年4月24日","autoDesc":true}');export{Le as comp,Ie as data};
