import{_ as c}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as p,o as r,c as u,a as s,b as e,d as a,w as n,e as l,f as t}from"./app-DmhNJ90i.js";const m={},g=t(`<h1 id="redis导航栏" tabindex="-1"><a class="header-anchor" href="#redis导航栏"><span>Redis导航栏</span></a></h1><h2 id="数据结构与redisobject" tabindex="-1"><a class="header-anchor" href="#数据结构与redisobject"><span>数据结构与RedisObject</span></a></h2><h3 id="_1简单动态字符串sds" tabindex="-1"><a class="header-anchor" href="#_1简单动态字符串sds"><span>①简单动态字符串SDS</span></a></h3><p>Redis的底层是用C语言实现的，但C语言字符串存在很多问题：</p><ul><li><p>获取字符串长度的需要通过运算</p></li><li><p>非字符串安全</p></li><li><p>不可修改</p></li></ul><p>因此Redis构建了一种新的字符串结构，称为简单动态字符串（Simple Dynamic String）简称SDS。</p><p>其中SDS是一个结构体，源码如下：</p><div class="language-c line-numbers-mode" data-ext="c" data-title="c"><pre class="language-c"><code><span class="token keyword">struct</span> <span class="token keyword">__attribute__</span><span class="token punctuation">(</span><span class="token punctuation">(</span>__packed__<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token class-name">sdshdr8</span> <span class="token punctuation">{</span>
    <span class="token class-name">uint8_t</span> len<span class="token punctuation">;</span>	<span class="token comment">//buf中已保存的字符串字节数，不包含结束标识</span>
    <span class="token class-name">uint8_t</span> alloc<span class="token punctuation">;</span>	<span class="token comment">//buf申请的总字节数，不包含结束标识</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">char</span> flags<span class="token punctuation">;</span>  <span class="token comment">//不同的SDS的头类型，用来控制SDS的头大小，对应关系如下SDS_TYPE定义</span>
    <span class="token keyword">char</span> buf<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">SDS_TYPE_5</span>  <span class="token expression"><span class="token number">0</span></span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">SDS_TYPE_8</span>  <span class="token expression"><span class="token number">1</span></span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">SDS_TYPE_16</span> <span class="token expression"><span class="token number">2</span></span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">SDS_TYPE_32</span> <span class="token expression"><span class="token number">3</span></span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">SDS_TYPE_64</span> <span class="token expression"><span class="token number">4</span></span></span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>example：一个&quot;hello&quot;字符串的SDS结构如下</p><figure><img src="http://images.xyzzs.top/image/image-20230122131601805.png_char" alt="image-20230122131601805" tabindex="0" loading="lazy"><figcaption>image-20230122131601805</figcaption></figure><p><mark>内存预分配</mark></p><p>SDS之所以叫做动态字符串，是因为它具备动态扩容的能力，例如一个内容为&quot;hi&quot;的SDS；</p><p>假如我们要给SDS追加一段字符串&quot;,zzs&quot;，这里首先会申请新内存空间：</p><ul><li>如果新字符串小于1M，则新空间为扩展后字符串长度的两倍+1；</li><li>如果新字符串大于1M，则新空间为扩展后字符串长度+1M+1，称为<em><strong>内存预分配</strong></em></li></ul><figure><img src="http://images.xyzzs.top/image/image-20230122133014915.png_char" alt="image-20230122133014915" tabindex="0" loading="lazy"><figcaption>image-20230122133014915</figcaption></figure><p><mark>优点</mark></p><ol><li>获取字符串长度的时间复杂度为O(1)</li><li>支持动态扩容</li><li>减少内存分配次数</li><li>二进制安全</li></ol><h3 id="_2intset—整数数组" tabindex="-1"><a class="header-anchor" href="#_2intset—整数数组"><span>②IntSet—整数数组</span></a></h3><p>IntSet是Redis中set集合的一种实现方式，基于整数数组来实现，并且具备长度可变、有序等特征。</p><div class="language-c line-numbers-mode" data-ext="c" data-title="c"><pre class="language-c"><code><span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token class-name">intset</span> <span class="token punctuation">{</span>
    <span class="token class-name">uint32_t</span> encoding<span class="token punctuation">;</span>	<span class="token comment">//编码方式，支持存放16位、32位、64位整数</span>
    <span class="token class-name">uint32_t</span> length<span class="token punctuation">;</span>	<span class="token comment">//元素个数</span>
    <span class="token class-name">int8_t</span> contents<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span>  <span class="token comment">//整数集合，保存集合数据</span>
<span class="token punctuation">}</span> intset<span class="token punctuation">;</span>

<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">INTSET_ENC_INT16</span> <span class="token expression"><span class="token punctuation">(</span><span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token class-name">int16_t</span><span class="token punctuation">)</span><span class="token punctuation">)</span> </span><span class="token comment">//2字节，范围类似java的short</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">INTSET_ENC_INT32</span> <span class="token expression"><span class="token punctuation">(</span><span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token class-name">int32_t</span><span class="token punctuation">)</span><span class="token punctuation">)</span> </span><span class="token comment">//4字节，范围类似java的int</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">INTSET_ENC_INT64</span> <span class="token expression"><span class="token punctuation">(</span><span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token class-name">int64_t</span><span class="token punctuation">)</span><span class="token punctuation">)</span> </span><span class="token comment">//8字节，范围类似java的long</span></span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>为了方便查找，Redis会将intset中所有的整数按照升序依次保存再contents数组中，结构如下</p><figure><img src="http://images.xyzzs.top/image/image-20230122135317734.png_char" alt="image-20230122135317734" tabindex="0" loading="lazy"><figcaption>image-20230122135317734</figcaption></figure><p>现在，数组中每个数字都在int16_t范围内，因此采用的编码方式是INTSET_ENC_INT16，占用的字节大小为：</p><ul><li>encoding：4 字节</li><li>length：4 字节</li><li>contents：2 字节 * 3 = 6 字节</li></ul><p><mark>IntSet升级</mark></p>`,25),h=t(`<figure><img src="http://images.xyzzs.top/image/image-20230122142031230.png_char" alt="image-20230122142031230" tabindex="0" loading="lazy"><figcaption>image-20230122142031230</figcaption></figure><p>现在，向该数组中添加一个数字：50000 ，这个数字超过了int16_t的范围，intset会自动升级编码方式到合适的大小。升级流程如下：</p><ol><li>升级编码为INTSET_ENC_INT32，每个整数占4个字节，并按照新的编码方式及元素个数扩容数组</li><li>倒序依次将数组中的元素拷贝到扩容的正确位置</li><li>将待添加元素放入数组末尾</li><li>最后，将intset的encoding属性改为INTSET_ENC_INT32，将length属性改为4</li></ol><figure><img src="http://images.xyzzs.top/image/image-20230122143827719.png_char" alt="image-20230122143827719" tabindex="0" loading="lazy"><figcaption>image-20230122143827719</figcaption></figure><p><mark>特点</mark></p><p>intset可以看做是特殊的整数数组，具备以下特点：</p><ol><li>Redis会确保IntSet中的元素唯一、有序</li><li>具备类型升级机制，可以节省内存空间</li><li>底层采用二分查找方式查询</li></ol><h3 id="_3dict—字典" tabindex="-1"><a class="header-anchor" href="#_3dict—字典"><span>③Dict—字典</span></a></h3><p>Redis是一个键值型的数据库，我们可以根据键实现快速的增删改查，这种关系一般通过Dict实现。</p><p>Dict由三部分组成，分别是字典（Dict）、哈希表（DictHashTable），哈希节点（DictEntry）。</p><div class="language-c line-numbers-mode" data-ext="c" data-title="c"><pre class="language-c"><code><span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token class-name">dict</span> <span class="token punctuation">{</span><span class="token comment">//字典</span>
    dictType <span class="token operator">*</span>type<span class="token punctuation">;</span>		<span class="token comment">//dict类型，内置不同的hash函数</span>
    <span class="token keyword">void</span> <span class="token operator">*</span>privdata<span class="token punctuation">;</span>		<span class="token comment">//私有数据，在做特殊hash运算时用</span>
    dictht ht<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">;</span>		<span class="token comment">//一个Dict包含两个哈希表，其中一个是当前数据，另一个一般是空，rehash时使用</span>
    <span class="token keyword">long</span> rehashidx<span class="token punctuation">;</span>		<span class="token comment">/*rehashidxrehash的进度，-1表示未进行 */</span>
    <span class="token class-name">int16_t</span> pauserehash<span class="token punctuation">;</span><span class="token comment">//rehash是否暂停，1则暂停，0继续</span>
<span class="token punctuation">}</span> dict<span class="token punctuation">;</span>

<span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token class-name">dictht</span> <span class="token punctuation">{</span><span class="token comment">//哈希表</span>
    dictEntry <span class="token operator">*</span><span class="token operator">*</span>table<span class="token punctuation">;</span>		<span class="token comment">//entry数组，保存的是指向entry的指针</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">long</span> size<span class="token punctuation">;</span>		<span class="token comment">//哈希表的大小</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">long</span> sizemask<span class="token punctuation">;</span>	<span class="token comment">//哈希表的大小的掩码，总等于size-1，用于哈希运算，按位与&amp; 效率高</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">long</span> used<span class="token punctuation">;</span>		<span class="token comment">//entry个数，因为节点可以形成链表，所以used可能会大于size</span>
<span class="token punctuation">}</span> dictht<span class="token punctuation">;</span>

<span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token class-name">dictEntry</span> <span class="token punctuation">{</span><span class="token comment">//哈希节点</span>
    <span class="token keyword">void</span> <span class="token operator">*</span>key<span class="token punctuation">;</span>	<span class="token comment">//键</span>
    <span class="token keyword">union</span> <span class="token punctuation">{</span>
        <span class="token keyword">void</span> <span class="token operator">*</span>val<span class="token punctuation">;</span>
        <span class="token class-name">uint64_t</span> u64<span class="token punctuation">;</span>
        <span class="token class-name">int64_t</span> s64<span class="token punctuation">;</span>
        <span class="token keyword">double</span> d<span class="token punctuation">;</span>
    <span class="token punctuation">}</span> v<span class="token punctuation">;</span>	<span class="token comment">//值</span>
    <span class="token keyword">struct</span> <span class="token class-name">dictEntry</span> <span class="token operator">*</span>next<span class="token punctuation">;</span>
<span class="token punctuation">}</span> dictEntry<span class="token punctuation">;</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><mark>Dict的结构</mark></p><ul><li>类似 Java 的 HashTable , 底层是数组加链表来解决哈希冲突</li><li>Dict 包含两个哈希表，ht[0]平常用，ht[1]用来rehash</li></ul><figure><img src="http://images.xyzzs.top/image/image-20230122151743360.png_char" alt="image-20230122151743360" tabindex="0" loading="lazy"><figcaption>image-20230122151743360</figcaption></figure><p><mark>Dict的扩容</mark></p><p>Dict的HashTable就是数组结合单向链表的实现，当集合中元素较多时，必然导致哈希冲突增多，链表过长，则查询效率会大大降低。</p><p>Dict在每次新增键值对时都会检查负载因子（LoadFactory = used / size）,满足以下两种情况会触发<em><strong>哈希表扩容</strong></em></p><ul><li>哈希表的LoadFactory &gt;= 1,并且服务器没有执行<code>BGSAVE</code> 或者<code>BGREWRITEAOF</code>等后台进程——因为类似命令对后台CPU使用是比较高的，影响性能</li><li>哈希表LoadFactory &gt; 5——此时链表应该是比较长，也比较影响性能</li></ul><p><mark>Dict的收缩</mark></p><p>Dict除了扩容外，每次删除元素时，也会对负载因子做检查，档loadFactory &lt; 0.1 时，会做哈希表收缩；</p><p><em><strong>Dict伸缩小结</strong></em></p><ul><li>当 LoadFactory 大于 5或者 LoadFactory 大于1 并且没有子进程任务时，Dict扩容；</li><li>当LoadFactory 小于 0.1 时，Dict 收缩；</li><li>扩容大小为第一个大于等于used + 1 的 2^n；</li><li>收缩大小为第一个大于等于used 的 2^n；</li><li>Dict采用渐进式rehash，每次访问Dict时执行一次rehash；</li><li>rehash时ht[0]只减不增，新增操作只在ht[1]执行，其他操作在两个哈希表；</li></ul>`,22),k=s("p",null,[e("不管扩容还是缩容，哈希表的大小size必定会变，导致sizemark变化，而key的查询与sizemark（参与哈希运算）有关，因此必须对哈希表的每一个key重新计算索引，插入新的哈希表，这个过程成为"),s("em",null,[s("strong",null,"rehash")]),e("，过程如下：")],-1),v=s("li",null,[e("计算hash的realSize，取决于当前要做的扩容还是收缩： "),s("ul",null,[s("li",null,[e("如果是扩容，则新size为第一个大于等于dict.ht[0].used+1的"),s("code",null,"2^n"),e("-")]),s("li",null,[e("如果是收缩，则新size为第一个大于等于dict.ht[0].used的"),s("code",null,"2^n"),e(" （不得小于4）")])])],-1),b=s("li",null,"按照新的realsize申请内存空间，创建dictht，并赋值给dict[1]",-1),_=s("li",null,"设置dict.rehashidx = 0 ,表示开始rehash",-1),y=s("li",null,"将dict.ht[1]赋值给dict.ht[0]，给dict.ht[1]初始化为空哈希表，释放原来的dict.ht[0]的内存",-1),f=s("li",null,"将rehashidx赋值为-1，代表rehash结束",-1),z=t('<h3 id="_4ziplist" tabindex="-1"><a class="header-anchor" href="#_4ziplist"><span>④ZipList</span></a></h3><p><mark>ZipList的结构</mark></p><figure><img src="http://images.xyzzs.top/image/image-20230122165636300.png_char" alt="image-20230122165636300" tabindex="0" loading="lazy"><figcaption>image-20230122165636300</figcaption></figure><figure><img src="http://images.xyzzs.top/image/1672572686250-43cefc51-74ef-4f95-bac1-b02267383d4c.png_char" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>ZipList是一种特殊的<code>双端链表</code>，由一系列特殊编码的连续内存块组成，可以在任意一端进行压入、弹出操作，并且该操作的时间复杂度为O(1)。</p><table><tr><td bgcolor="red">属性</td><td bgcolor="red">类型</td><td bgcolor="red">长度</td><td bgcolor="red">用途</td></tr><tr><td>zlbytes</td><td>uint32_t</td><td>4字节</td><td>记录整个压缩列表占用的内存字节数</td></tr><tr><td>zltail</td><td>uint32_t</td><td>4字节</td><td>记录压缩列表表尾节点距离压缩列表的起始地址有多少字节，通过这个偏移量，可以确定表尾节点的地址。</td></tr><tr><td>zllen</td><td>uint16_t</td><td>2字节</td><td>记录了压缩列表包含的节点数量。最大值为uint16_max（65534），如果超过这个值，此处会记录65535，但节点的真实数量需要遍历整个压缩列表才能计算得出。因此ziplist不介意存过多数据</td></tr><tr><td>entry</td><td>列表节点</td><td>不定</td><td>压缩列表包含的各个节点，节点的长度由节点保存的内容决定</td></tr><tr><td>zlend</td><td>uint8_t</td><td>1</td><td> 特殊值0xFF（十进制255），用于标记压缩列表的末端</td></tr></table><p><mark>ZipListEntry</mark></p><p>ZipList中的Entry并不像普通链表那样记录前后节点的指针，因为记录两个指针要占用16个字节，浪费内存；而是采用如下结构：</p><figure><img src="http://images.xyzzs.top/image/image-20230122182941880.png_char" alt="image-20230122182941880" tabindex="0" loading="lazy"><figcaption>image-20230122182941880</figcaption></figure>',9),x=s("ul",null,[s("li",null,"如果前一节点的长度小于254字节，则采用1个字节来保存这个长度值"),s("li",null,"如果前一节点的长度大于254字节，则采用5个字节来保存这个长度值，第一个字节为0xFE，后四个字节才是真实长度数据")],-1),S=s("li",null,"contents：负责保存节点的数据，可以是字符串或整数",-1),R=s("figure",null,[s("img",{src:"http://images.xyzzs.top/image/1672573411313-8b9048b4-f2a9-403d-ae93-acfdd2491764.png_char",alt:"img",tabindex:"0",loading:"lazy"}),s("figcaption",null,"img")],-1),L=s("figure",null,[s("img",{src:"http://images.xyzzs.top/image/1672573831777-b96f8724-444e-46ea-80e4-87486ced62c8.png_char",alt:"img",tabindex:"0",loading:"lazy"}),s("figcaption",null,"img")],-1),O=s("p",null,[s("mark",null,"Encoding编码属性")],-1),D=s("p",null,"ZipListEntry中的encoding编码分为字符串和整数两种：",-1),T=s("p",null,"字符串：如果encoding是以00、01、10开头，则证明content是字符串",-1),w=s("thead",null,[s("tr",null,[s("th",null,"编码"),s("th",null,"编码长度"),s("th",null,"字符串大小")])],-1),E=s("td",null,"1 bytes",-1),N=s("td",null,"<= 63 bytes，6个比特位记录长度",-1),I=s("td",null,"2 bytes",-1),A=s("td",null,"<= 16383 bytes，14个比特位记录长度",-1),B=s("td",null,"5 bytes",-1),F=s("td",null,"<= 4294967295 bytes，32个比特位记录长度",-1),Z=t("<li><p>整数：如果encoding是以11开头，则说明content是整数，且encoding固定只占用一个字节</p><table><thead><tr><th>编码</th><th>编码长度</th><th>整数类型</th></tr></thead><tbody><tr><td>11000000</td><td>1 bytes</td><td>int16_t(2 bytes)</td></tr><tr><td>11010000</td><td>1 bytes</td><td>int32_t(4 bytes)</td></tr><tr><td>11100000</td><td>1 bytes</td><td>int64_t(8 bytes)</td></tr><tr><td>11110000</td><td>1 bytes</td><td>24位有符号整数(3 bytes)</td></tr><tr><td>11111110</td><td>1 bytes</td><td>8位有符号整数(1 bytes)</td></tr><tr><td>1111xxxx</td><td>1 bytes</td><td>直接在xxxx位置保存数值，范围从0001~1101，减1后结果为实际值；<br> 不再需要content</td></tr></tbody></table></li>",1),q=s("figure",null,[s("img",{src:"http://images.xyzzs.top/image/1672574517911-630ccdf9-60ce-4185-bdfc-026981d4e31e.png_char",alt:"img",tabindex:"0",loading:"lazy"}),s("figcaption",null,"img")],-1),C=s("p",null,[s("mark",null,"ZipList的连锁更新问题")],-1),P=s("p",null,"ZipList的每个Entry都包含previous_entry_length来记录上一个节点的大小，长度是1或5个字节",-1),H=s("ul",null,[s("li",null,"如果前一节点的长度小于254字节，则采用1个字节来保存这个长度值"),s("li",null,"如果前一节点的长度大于等于254字节，则采用5个字节来保存这个长度值，第一个字节为0xfe，后四个字节才是真实长度数据。")],-1),M=s("strong",null,"连锁更新",-1),j=t('<p><mark>ZipList特性</mark></p><ol><li>压缩列表可以看做一种连续内存空间的&quot;双向链表&quot;</li><li>列表的节点之间不是通过指针连接，而是记录上一节点和本节点长度来寻址，内存占用较低</li><li>如果列表数据过多，导致链表过长，可能影响查询性能</li><li>增或删较大数据时有可能发生连续更新问题</li></ol><h3 id="_5quicklist" tabindex="-1"><a class="header-anchor" href="#_5quicklist"><span>⑤QuickList</span></a></h3><p>问题1： ZipList 虽然节省内存，但申请内存必须是连续空间，如果内存占用较多，申请效率很低，怎木办？</p><p>为了缓解这个问题，我们必须限制 ZipList 的长度和entry大小</p><p>问题2：但是我们就是要存储大量数据，超出了 ZipList 最佳上限该怎么办？</p><p>我们可以创建多个 ZipList 来分片存储数据。</p><p>问题3：数据拆分后比价分散，比方便管理和查找，这多个 ZipList 如何建立联系？</p><p>Redis 在3.2版本引用了新的数据结构 QuickList，它是一个双端链表，只不过链表中的每个 节点都是一个ZipList。</p><p><mark>QuickList总体结构</mark></p><figure><img src="http://images.xyzzs.top/image/image-20230122192805321.png_char" alt="image-20230122192805321" tabindex="0" loading="lazy"><figcaption>image-20230122192805321</figcaption></figure><p><mark>避免QuickList过大</mark></p>',12),G=t(`<p>为了避免QuickList中的每个ZipList的entry过多，Redis提供了一个配置项：list-max-ziplist-size来限制。</p><ul><li><p>如果值为正，则代表ZipList的允许的entry个数的最大值；</p></li><li><p>如果值为负，则代表ZipList的最大内存大小，分5种情况：</p><ol><li>-1：每个ZipList的内存占用不能超过4kb</li><li>-2：每个ZipList的内存占用不能超过8kb（默认值）</li><li>-3：每个ZipList的内存占用不能超过16kb</li><li>-4：每个ZipList的内存占用不能超过32kb</li><li>-5：每个ZipList的内存占用不能超过64kb</li></ol><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>config get list-max-ziplist-size
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><figure><img src="http://images.xyzzs.top/image/image-20230122193828142.png_char" alt="image-20230122193828142" tabindex="0" loading="lazy"><figcaption>image-20230122193828142</figcaption></figure></li></ul>`,2),Y=t(`<p>​ 除了控制ZipList的大小，QuickList还可以对节点的ZipList做压缩。通过配置项list-compress-depth来控制。因为链表一般都是从首尾访问较多，所以首尾是不压缩的。这个参数是控制首尾不压缩的节点个数：</p><ul><li>0：特殊值，代表不压缩（默认）</li><li>1：表示QuickList的的首尾各有1个节点不压缩，中间节点压缩</li><li>2：表示QuickList的的首尾各有2个节点不压缩，中间节点压缩</li><li>以此类推</li></ul><figure><img src="http://images.xyzzs.top/image/image-20230122195421913.png_char" alt="image-20230122195421913" tabindex="0" loading="lazy"><figcaption>image-20230122195421913</figcaption></figure><p><mark>结构及源码</mark></p><div class="language-c line-numbers-mode" data-ext="c" data-title="c"><pre class="language-c"><code><span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token class-name">quicklist</span> <span class="token punctuation">{</span>
    quicklistNode <span class="token operator">*</span>head<span class="token punctuation">;</span>
    quicklistNode <span class="token operator">*</span>tail<span class="token punctuation">;</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">long</span> count<span class="token punctuation">;</span>        <span class="token comment">/* total count of all entries in all ziplists */</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">long</span> len<span class="token punctuation">;</span>          <span class="token comment">/* number of quicklistNodes */</span>
    <span class="token keyword">int</span> fill <span class="token operator">:</span> QL_FILL_BITS<span class="token punctuation">;</span>              <span class="token comment">/* fill factor for individual nodes */</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">int</span> compress <span class="token operator">:</span> QL_COMP_BITS<span class="token punctuation">;</span> <span class="token comment">/* depth of end nodes not to compress;0=off */</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">int</span> bookmark_count<span class="token operator">:</span> QL_BM_BITS<span class="token punctuation">;</span>
    quicklistBookmark bookmarks<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span> quicklist<span class="token punctuation">;</span>

<span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token class-name">quicklistNode</span> <span class="token punctuation">{</span>
    <span class="token keyword">struct</span> <span class="token class-name">quicklistNode</span> <span class="token operator">*</span>prev<span class="token punctuation">;</span>
    <span class="token keyword">struct</span> <span class="token class-name">quicklistNode</span> <span class="token operator">*</span>next<span class="token punctuation">;</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">char</span> <span class="token operator">*</span>zl<span class="token punctuation">;</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">int</span> sz<span class="token punctuation">;</span>             <span class="token comment">/* ziplist size in bytes */</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">int</span> count <span class="token operator">:</span> <span class="token number">16</span><span class="token punctuation">;</span>     <span class="token comment">/* count of items in ziplist */</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">int</span> encoding <span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">;</span>   <span class="token comment">/* RAW==1 or LZF==2 */</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">int</span> container <span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">;</span>  <span class="token comment">/* NONE==1 or ZIPLIST==2 */</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">int</span> recompress <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">;</span> <span class="token comment">/* was this node previous compressed? */</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">int</span> attempted_compress <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">;</span> <span class="token comment">/* node can&#39;t compress; too small */</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">int</span> extra <span class="token operator">:</span> <span class="token number">10</span><span class="token punctuation">;</span> <span class="token comment">/* more bits to steal for future usage */</span>
<span class="token punctuation">}</span> quicklistNode<span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="http://images.xyzzs.top/image/image-20230122200438739.png_char" alt="image-20230122200438739" tabindex="0" loading="lazy"><figcaption>image-20230122200438739</figcaption></figure><p><mark>特点</mark></p><ul><li>是一个节点为ZipList的双端链表</li><li>节点采用ZipList，解决了传统链表的内存占用问题</li><li>控制了ZipList大小，解决连续内存空间申请效率问题</li><li>中间节点可以压缩，进一步节省了内存</li></ul><h3 id="_6skiplist" tabindex="-1"><a class="header-anchor" href="#_6skiplist"><span>⑥SkipList</span></a></h3><p>SkipList首先是链表，但与传统链表相比有几点差异：</p><ul><li>元素按照升级排列存储</li><li>节点可能包含多个指针（最多有32级），指针跨度不同</li></ul><figure><img src="http://images.xyzzs.top/image/image-20230122202833688.png_char" alt="image-20230122202833688" tabindex="0" loading="lazy"><figcaption>image-20230122202833688</figcaption></figure><p><mark>特点</mark></p><ul><li>跳跃表是一个双向链表，每个节点都包含score和ele值</li><li>节点按照score值排序，score值一样则按照ele字典排序</li><li>每个节点都可以包含多层指针，层数是1到32之间的随机数（根据算法去推测）</li><li>不同层指针到下一个节点的跨度不同，层级越高，跨度越大</li><li>增删改查效率与红黑树基本一直，实现却更简单</li></ul><h3 id="redisobject" tabindex="-1"><a class="header-anchor" href="#redisobject"><span>RedisObject</span></a></h3><p>Redis中的任意数据类型的键和值都会被封装为一个RedisObject，也叫做Redis对象</p><figure><img src="http://images.xyzzs.top/image/image-20230122204056965.png_char" alt="image-20230122204056965" tabindex="0" loading="lazy"><figcaption>image-20230122204056965</figcaption></figure><p>Redis中会根据存储的数据类型不同，选择不同的编码方式，共包含11种不同类型：</p><table><thead><tr><th>编号</th><th>编码方式</th><th>说明</th></tr></thead><tbody><tr><td>0</td><td>OBJ_ENCODING_RAW</td><td>raw编码动态字符串</td></tr><tr><td>1</td><td>OBJ_ENCODING_INT</td><td>long类型的整数的字符串</td></tr><tr><td>2</td><td>OBJ_ENCODING_HT</td><td>hash表（字典dict）</td></tr><tr><td>3</td><td>OBJ_ENCODING_ZIPMAP</td><td>已废弃</td></tr><tr><td>4</td><td>OBJ_ENCODING_LINKEDLIST</td><td>双端链表</td></tr><tr><td>5</td><td>OBJ_ENCODING_ZIPLIST</td><td>压缩列表啊</td></tr><tr><td>6</td><td>OBJ_ENCODING_INTSET</td><td>整数集合</td></tr><tr><td>7</td><td>OBJ_ENCODING_SKIPLIST</td><td>跳表</td></tr><tr><td>8</td><td>OBJ_ENCODING_EMBSTR</td><td>embstr的动态字符串</td></tr><tr><td>9</td><td>OBJ_ENCODING_QUICKLIST</td><td>快速列表</td></tr><tr><td>10</td><td>OBJ_ENCODING_STREAM</td><td>Stream流</td></tr></tbody></table><p>Redis中会根据存储的数据类型不同，选择不同的编码方式。每种数据类型使用的编码方式 如下：</p><table><thead><tr><th>数据类型</th><th>编码方式</th></tr></thead><tbody><tr><td>OBJ_STRING</td><td>int、embstr、raw</td></tr><tr><td>OBJ_LIST</td><td>LinkedList和ZipList（3.2之前）、QuickList（3.2以后）</td></tr><tr><td>OBJ_SET</td><td>intset、HT</td></tr><tr><td>OBJ_ZSET</td><td>ZipList、HT、SkipList</td></tr><tr><td>OBJ_HASH</td><td>ZipList、HT</td></tr></tbody></table><h2 id="五种常用数据类型" tabindex="-1"><a class="header-anchor" href="#五种常用数据类型"><span>五种常用数据类型</span></a></h2><h3 id="底层实现——string" tabindex="-1"><a class="header-anchor" href="#底层实现——string"><span>底层实现——String</span></a></h3><p>String是Redis中最常见的数据存储类型：</p>`,24),J=s("mark",null," RAW ",-1),Q=s("figure",null,[s("img",{src:"http://images.xyzzs.top/image/image-20230123104322060.png_char",alt:"image-20230123104322060",tabindex:"0",loading:"lazy"}),s("figcaption",null,"image-20230123104322060")],-1),U=s("mark",null,"EMBSTR编码",-1),K=s("figure",null,[s("img",{src:"http://images.xyzzs.top/image/image-20230123104423346.png_char",alt:"image-20230123104423346",tabindex:"0",loading:"lazy"}),s("figcaption",null,"image-20230123104423346")],-1),V=s("mark",null,"INT编码",-1),W=s("figure",null,[s("img",{src:"http://images.xyzzs.top/image/image-20230123104535027.png_char",alt:"image-20230123104535027",tabindex:"0",loading:"lazy"}),s("figcaption",null,"image-20230123104535027")],-1),X=t('<p>客户端验证</p><figure><img src="http://images.xyzzs.top/image/image-20230123105908327.png_char" alt="image-20230123105908327" tabindex="0" loading="lazy"><figcaption>image-20230123105908327</figcaption></figure><h3 id="底层实现——list" tabindex="-1"><a class="header-anchor" href="#底层实现——list"><span>底层实现——List</span></a></h3><p>List类型可以从队首、队尾操作列表中的元素</p><img src="http://images.xyzzs.top/image/image-20230123113427574.png_char" alt="image-20230123113427574" style="zoom:45%;"><p>分析：哪种数据更能满足以上特征？</p><ul><li>LinkedList：普通链表，可以从双端访问，内存占用较高，内存碎片较多</li><li>ZipList：压缩列表，可以从双端访问，内存占用较低，存储上限低</li><li>QuickList：可以从双端访问，内存占用较低，包含多个ZipList，存储上限高</li></ul><p><mark>List底层实现</mark></p>',8),$=s("li",null,"在3.2版本之前，Redis采用ZipList和LinkedList来实现List，当元素数量小于512并且元素大小小于64字节时采用ZipList编码，超过则采用LinkedList编码",-1),ss=t('<figure><img src="http://images.xyzzs.top/image/image-20230123122029937.png_char" alt="image-20230123122029937" tabindex="0" loading="lazy"><figcaption>image-20230123122029937</figcaption></figure><h3 id="底层实现——set" tabindex="-1"><a class="header-anchor" href="#底层实现——set"><span>底层实现——Set</span></a></h3><p>Set是Redis的中单列集合，满足以下特点：</p><ul><li>不保证有序性</li><li>保证元素唯一（可以判断元素是否存在）</li><li>求交集、并集、差集，查询效率要求高</li></ul><img src="http://images.xyzzs.top/image/image-20230123123941680.png_char" alt="image-20230123123941680" style="zoom:50%;"><p><mark>Set底层实现</mark></p>',6),es=s("code",null,"null",-1),as=t('<figure><img src="http://images.xyzzs.top/image/image-20230123125355831.png_char" alt="image-20230123125355831" tabindex="0" loading="lazy"><figcaption>image-20230123125355831</figcaption></figure><h3 id="底层实现——zset" tabindex="-1"><a class="header-anchor" href="#底层实现——zset"><span>底层实现——ZSet</span></a></h3><p>ZSet也就是SortedSet，其中每一个元素都需要指定一个score值和member值，且满足以下特征：</p><ul><li><p>可以根据score值排序（有序）</p></li><li><p>member必须唯一（键唯一）</p></li><li><p>可以根据member查询分数（键值存储，效率）</p><figure><img src="http://images.xyzzs.top/image/image-20230123130324355.png_char_char" alt="image-20230123130324355" tabindex="0" loading="lazy"><figcaption>image-20230123130324355</figcaption></figure></li></ul><p>回顾：</p>',5),ns=s("p",null,"小孩子才做选择，我们全都要：",-1),is=s("ul",null,[s("li",null,[s("p",null,"Dict 来实现键值存储，键的唯一")]),s("li",null,[s("p",null,"SkipList 实现可排序"),s("img",{src:"http://images.xyzzs.top/image/image-20230123132144199.png_char_char",alt:"image-20230123132144199",style:{zoom:"50%"}})])],-1),ts=s("strong",null,"更耗内存",-1),ls=s("ul",null,[s("li",null,"元素数量小于zset-max-ziplist-entries，默认值128"),s("li",null,"每个元素都小于zset-max-ziplist-value字节，默认值64")],-1),ps=s("p",null,"ZipList本身没有排序功能，而且没有键值对的概念，因此需要有由 zset 通过编码实现：",-1),os=s("p",null,"🔷ZipList是联系内存，因此score和element是紧挨在一起的两个entry，element在前，score在后;",-1),ds=s("p",null,"🔷score越小越接近队首，score越大越接近队尾，按照score值升序排列",-1),cs=s("figure",null,[s("img",{src:"http://images.xyzzs.top/image/image-20230123135653225.png_char_char",alt:"",tabindex:"0",loading:"lazy"}),s("figcaption")],-1),rs=t(`<div class="language-c line-numbers-mode" data-ext="c" data-title="c"><pre class="language-c"><code><span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token class-name">zset</span> <span class="token punctuation">{</span>
    <span class="token comment">// Dict指针</span>
    dict <span class="token operator">*</span>dict<span class="token punctuation">;</span>
    <span class="token comment">// SkipList指针</span>
    zskiplist <span class="token operator">*</span>zsl<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="底层实现——hash" tabindex="-1"><a class="header-anchor" href="#底层实现——hash"><span>底层实现——Hash</span></a></h3><p>Hash结构与ZSet比价类似：</p><ul><li>都是键值存储</li><li>都需要根据键获取值</li><li>键必须唯一</li></ul><p>但也有区别：</p><p>ZSet 的键是member，值是score，必须为数字，以此来排序，有序；</p><p>hash的键和值都是任意值，无序</p><p>因此，Hash底层采用的编码与Zset也基本一直，只需把排序有关的SkipList去掉即可</p>`,8),us=s("li",null,[s("p",null,"Hash结构默认采用ZipList编码，用以节省内存，相邻的两个entry分别保存field和value")],-1),ms=s("p",null,"当数据量较大时，Hash结构会转为HT编码，也就是Dict，触发条件有两",-1),gs=s("figure",null,[s("img",{src:"http://images.xyzzs.top/image/image-20230123142800925.png_char",alt:"image-20230123142800925",tabindex:"0",loading:"lazy"}),s("figcaption",null,"image-20230123142800925")],-1),hs=t('<figure><img src="http://images.xyzzs.top/image/image-20230123142606904.png_char" alt="image-20230123142606904" tabindex="0" loading="lazy"><figcaption>image-20230123142606904</figcaption></figure><h3 id="使用场景" tabindex="-1"><a class="header-anchor" href="#使用场景"><span>使用场景</span></a></h3><ol><li><p>string</p><ul><li>常规key-value缓存应用。</li><li>常规计数功能，如粉丝数；点赞</li><li>分布式锁。</li></ul></li><li><p>hash</p><ul><li>存放结构化数据，如用户信息（昵称、年龄、性别、积分等），对应Java中的 Map&lt;String,map&lt;Object,Object&gt;&gt;</li><li>购物车（限小中厂）</li></ul></li><li><p>list</p><ul><li>热门博客列表、文章订阅</li><li>消息队列系统。使用list可以构建队列系统，比如：将Redis用作日志收集器，多个端点将日志信息写入Redis，然后一个worker统一将所有日志写到磁盘。</li><li>秒杀抢购场景</li></ul></li><li><p>set</p><ul><li>好友关系，微博粉丝的共同关注、共同喜好、共同好友等</li><li>利用唯一性，统计访问网站的所有独立ip</li><li>小程序抽奖</li><li>微信朋友圈点赞</li><li>微博内好友关注社交关系</li><li>推送可能认识的人</li></ul></li><li><p>zset：</p><ul><li>排行榜：热搜榜等</li><li>优先级队列</li><li>对商品进行排序显示</li></ul></li></ol><h3 id="常见命令操作" tabindex="-1"><a class="header-anchor" href="#常见命令操作"><span>常见命令操作</span></a></h3>',4),ks={href:"http://redis.cn/commands.html#",target:"_blank",rel:"noopener noreferrer"},vs=t(`<hr><ol><li><p>String</p><ul><li><p>SET：添加或修改意见存在的一个String类型的键值对</p></li><li><p>GET：根据key获取String类型的value</p></li><li><p>MSET：批量添加多个String类型的键值对</p></li><li><p>MGET：根据多个key获取多个String类型的value</p></li><li><p>INCR：让一个整型的key自增1</p></li><li><p>INCRBY：让一个整型的key自增并指定步长</p></li><li><p>INCRBYFLOAT：让一个浮点类型的数字自增并指定步长</p></li><li><p>SETNX：添加一个String类型的键值对，前提是这个key不存在，否则不执行</p></li><li><p>SETEX：添加一个String类型的键值对，并且指定有效期</p></li><li><p>APPEND：追加一个值到key上</p></li><li><p>STRLEN：获取指定 key的长度</p></li><li><p>KEYS和SCAN：<code>KEYS</code>指令会导致线程阻塞一段时间，直到执行完毕，服务才能恢复。<code>SCAN</code>采用渐进式遍历的方式来解决<code>KEYS</code>命令可能带来的阻塞问题，每次<code>SCAN</code>命令的时间复杂度是O(1)，但是要真正实现<code>KEYS</code>的功能，需要执行多次<code>SCAN</code>。</p><p>scan的缺点：在<code>SCAN</code>的过程中如果有键的变化（增加、删除、修改），遍历过程可能会有以下问题：新增的键可能没有遍历到，遍历出了重复的键等情况，也就是说scan并不能保证完整的遍历出来所有的键。</p><p><strong>警告</strong>: <code>KEYS</code> 的速度非常快，但在一个大的数据库中使用它仍然可能造成性能问题，如果你需要从一个数据集中查找特定的 key， 你最好还是用 Redis 的集合结构 Set 来代替。</p></li></ul></li><li><p>Hash</p><ul><li>HSET：添加或修改hash类型key的field的值。<code>HSET myhash field1 &quot;Hello&quot;</code></li><li>HGET：返回 key 指定的哈希集中该字段所关联的值。<code>HGET myhash field1</code></li><li>HMSET：批量添加多个hash类型的key的field的值。<code>HMSET myhash field1 &quot;Hello&quot; field2 &quot;World&quot;</code></li><li>HMGET：批量获取多个hash类型的key的field的值。<code>HMGET myhash field1 field2 nofield</code></li><li>HGETALL：获取一个hash类型的key中的所有field的和value。</li><li>HKEYS：获取一个hash类型的key中的所有field。</li><li>HAVLS：获取一个hash类型的key中的所有value。</li><li>HINCRBY：让一个hash类型key的字段值自增并指定步长。</li><li>HSETNX：添加一个hash类型的key的field值，前提是这个field不存在，否则不执行。</li></ul></li><li><p>List</p><ul><li>LPUSH：向列表左侧插入一个或多个元素</li><li>LPOP：移除并返回列表左侧的第一个元素，没有则返回<code>nil</code></li><li>RPUSH：向列表右侧插入一个或多个元素</li><li>RPOP：移除并返回列表右侧的第一个元素，没有则返回<code>nil</code></li><li>LRANGE：返回一段角标范围内的所有元素</li><li>BLPOP 和 BRPOP：与 LPOP 和 RPOP 类似，只不过在没有元素时等待指定时间，而不是直接返回<code>nil</code></li><li>LTRIM：删除索引1到2以外的所有元素<code>LTRIM numbers 1 2</code></li><li>LREM：从存于 key 的列表里移除前 count 次出现的值为 value 的元素。 这个 count 参数通过下面几种方式影响这个操作：<code>LREM numbers 0 2</code><ul><li>count &lt; 0, 则从右边开始删除前count个值为value的元素</li><li>count &gt; 0, 则从左边开始删除前count个值为value的元素</li><li>count = 0, 则删除所有值为value的元素</li></ul></li></ul></li><li><p>Set</p><ul><li>SADD：向set中添加一个或多个元素</li><li>SREM：移除set中的指定元素</li><li>SCARN：返回set中元素的个数</li><li>SISMEMBER：判断一个元素是否存在set中</li><li>SMEMBERS：获取set中的所有元素</li><li>SINTER：交集，都有的</li><li>SDIFF：差集，一个集合中有，另一个集合中没有</li><li>SUNION：并集，合并后去掉重复元素</li></ul></li><li><p>Zset</p><ul><li>ZADD：添加一个或多个元素到sorted set，如果已经存在则更新score值</li><li>ZREM：删除sorted set中的一个指定元素</li><li>ZSCORE：获取sorted set中的指定元素的score值</li><li>ZRANK：获取sorted set中的指定元素的排名</li><li>ZCARD：获取sorted set中的元素个数</li><li>ZCOUNT：统计score值在给定范围内的所有元素个数</li><li>ZINCRBY：让sorted set中的指定元素自增，步长为指定的increment值</li><li>ZRANGE：按照score排序后，获取指定排名范围内的元素</li><li>ZRANGBYSCORE：按照score排序后，获取指定score范围内的元素</li><li>ZDIFF、ZINTER、ZUNION：求差集、交集、并集</li></ul></li></ol><h2 id="持久策略" tabindex="-1"><a class="header-anchor" href="#持久策略"><span>持久策略</span></a></h2><h3 id="rdb" tabindex="-1"><a class="header-anchor" href="#rdb"><span>RDB</span></a></h3><p>redis database backup file（Redis数据备份文件 ）</p><div class="language-java line-numbers-mode" data-ext="java" data-title="java"><pre class="language-java"><code>save<span class="token operator">:</span>由redis主进程执行rdb，会阻塞所有命令，等待执行完成后返回ok<span class="token operator">-</span>适用服务宕机、停机之前
bgsave<span class="token operator">:</span>开启子进程执行rdb，避免主进程受到影响，执行后立即<span class="token class-name">Background</span> saving started<span class="token operator">-</span>适用使用中
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="http://images.xyzzs.top/image/image-20230123205540797.png_char" alt="image-20230123205540797" tabindex="0" loading="lazy"><figcaption>image-20230123205540797</figcaption></figure><p>Redis内部有触发RDB的机制，可以在redis.conf文件中配置：</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code># 900 秒内如果至少有1个key被修改，则执行bgsave
save 900 1
save 300 10 
save 60  10000

# 表示禁用RDB
save &quot;&quot;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>RDB其他配置也可以在redis.conf文件中配置：</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code># 是否压缩，建议不开启，压缩会消耗cpu，磁盘的话不值钱
rdbcompression yes
# RDB文件名
dbfilename dump.rdb
# 文件保存的路径目录
dir ./
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><hr><p>RDB方式bgsave的主要基本流程如下：</p><ol><li>fork主进程得到一个子进程，共享内存空间</li><li>子进程读取内存数据并写入新的RDB文件</li><li>用新RDB文件替换旧的RDB文件</li></ol><p>fork采用的是copy-on-write技术：</p><ul><li><p>当主进程执行读操作时，访问共享内存</p></li><li><p>当主进程执行写操作时，则会拷贝一份数据，执行写操作</p><p>⚠️假设在进行RDB进行过程中，所有数据都有写操作请求，此时占用内存相当于两倍！</p></li></ul><figure><img src="http://images.xyzzs.top/image/image-20230123213045653.png_char" alt="image-20230123213045653" tabindex="0" loading="lazy"><figcaption>image-20230123213045653</figcaption></figure><hr><p>RDB执行时机：</p><ol><li>手动</li></ol><ul><li>执行<code>SAVE</code>命令或执行<code>BGSAVE</code>命令</li></ul><ol start="2"><li>被动触发</li></ol><ul><li>根据配置规则进行自动快照，如<code>SAVE 300 10</code>,300秒内至少有10个键被修改则进行快照。</li><li>如果从节点执行全量复制操作，主节点自动执行bgsave生成RDB文件并发送给从节点。</li><li>默认情况下执行shutdown命令时，如果没有开启AOF持久化功能则自动执行bgsave。</li><li>执行debug reload命令重新加载Redis时，也会自动触发save操作。</li></ul><hr><p>RDB优缺点：</p><p>👍①RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。</p><p>②占用空间很小，它保存了 Redis 某个时间点的数据集，很适合用于做备份。</p><p>③适用于灾难恢复，它只有一个文件，并且内容都非常紧凑，可以（在加密后）将它传送到别的数据中心。</p><p>👎① RDB 执行间隔时间长，两次 RDB 之间写入数据有丢失的风险；</p><p>​ ② fork 子进程、压缩、写出 RDB 文件都比较耗时</p><h3 id="aof" tabindex="-1"><a class="header-anchor" href="#aof"><span>AOF</span></a></h3><p>append only file（追加文件）</p><p>AOF默认是关闭的，需要修改redis.conf配置文件来开启AOF</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code># 是否开启AOF功能，默认是no
appendonly yes
# AOF文件的名称
appendfilename &quot;appendonly.aof&quot;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>AOF记录命令的频率也可以通过redis.conf文件来配置</p><div class="language-java line-numbers-mode" data-ext="java" data-title="java"><pre class="language-java"><code># 表示每执行一次写命令，立即记录到<span class="token constant">AOF</span>文件
appendfsync always
# 写命令执行完先放入<span class="token constant">AOF</span>缓冲器，然后表示每隔<span class="token number">1</span>秒将缓冲区数据写到<span class="token constant">AOF</span>文件，是默认方案
appendfsync everysec 
# 写命令执行完现放入<span class="token constant">AOF</span>缓冲区，由操作系统决定何时将缓冲区内容写回磁盘
appendfsync no
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><table><thead><tr><th>配置项</th><th>刷盘实际</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>Always</td><td>同步刷盘</td><td>可靠性高，几乎不丢数据</td><td>性能开销大</td></tr><tr><td>everysec</td><td>每秒刷盘</td><td>性能适中</td><td>最多丢失1秒数据</td></tr><tr><td>no</td><td>操作系统控制</td><td>性能最佳</td><td>可靠性较差，可能丢失大量数据</td></tr></tbody></table><p>Redis处理的每一个写命令都会记录在AOF文件中</p><ul><li><p>everysec（默认）: 每秒调用 fsync, Redis 性能和数据安全性适</p></li><li><p>always: 在每次写入 appendonly 日志之后调用 fsync，速度最慢但是数据安全性最高。</p></li><li><p>no: 不调用 fsync, 让操作系统在需要时刷新数据，速度最快。</p></li></ul>`,39),bs=t(`<img src="http://images.xyzzs.top/image/image-20230123234111639.png_char" alt="image-20230123234111639" style="zoom:50%;"><p>Redis也会在触发阈值时自动去重写AOF文件。阈值也可以在redis.conf中配置：</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>#开启：AOF 重写由两个参数共同控制，auto-aof-rewrite-percentage 和 auto-aof-rewrite-min-size，同时满足这两个条件，则触发 AOF 后台重写 BGREWRITEAOF。
# AOF 文件比上次文件，增长超过多少百分比则触发重写
auto-aof-rewrite-percentage 100
# AOF文件体积最小多大以上才触发重写
auto-aof-rewrite-min-size 64mb

# 关闭：auto-aof-rewrite-percentage 0，指定0的百分比，以禁用自动AOF重写功能。
auto-aof-rewrite-percentage 0
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>同时满足这两个条件</p><p>假设 AOF 的日志现在 128mb ，如果发现增长的比例，超过了之前的100%，即 256 mb ，就可能会去触发一次rewrite，但是此时还要去跟 min-size ：64 mb 去比较， 256 mb &gt; 64 mb ，才会去触发rewrite</p><hr><p>AOF破损文件的修复：</p><p>如果redis在append数据到AOF文件时，机器宕机了，可能会导致AOF文件破损</p><p>用redis-check-aof --fix命令来修复破损的AOF文件</p><hr><p>两种方式对比</p><table><thead><tr><th></th><th>RDB</th><th>AOF</th></tr></thead><tbody><tr><td>持久化方式</td><td>定时对整个内存做快照</td><td>记录每一次执行的命令</td></tr><tr><td>数据完整性</td><td>不完整，两次备份之间会丢失</td><td>相对完整，取决于刷盘策略</td></tr><tr><td>文件大小</td><td>会有压缩，文件体积小</td><td>记录命令，文件体积很大， bgwriteao可重写</td></tr><tr><td>宕机恢复速度</td><td>很快</td><td>慢</td></tr><tr><td>数据恢复优先级</td><td>低，因为数据完整性不如AOF</td><td>高，因为数据完整性更高</td></tr><tr><td>系统资源占用</td><td>高，大量CPU和内存消耗</td><td>低，主要是磁盘IO资源，但AOF重写时会占用大量CPU和内存资源</td></tr><tr><td>使用场景</td><td>可以容忍数分钟的数据丢失，追求更快的启动速度</td><td>对数据安全性要求较高</td></tr></tbody></table><h3 id="混合持久化" tabindex="-1"><a class="header-anchor" href="#混合持久化"><span>混合持久化</span></a></h3><p>​ 混合持久化并不是一种全新的持久化方式，而是对已有方式的优化。混合持久化只发生于 AOF 重写过程。使用了混合持久化，重写后的新 AOF 文件前半段是 RDB 格式的全量数据，后半段是 AOF 格式的增量数据。</p>`,14),_s=s("p",null,"​ 混合持久化本质是通过 AOF 后台重写（bgrewriteaof 命令）完成的，不同的是当开启混合持久化时，fork 出的子进程先将当前全量数据以 RDB 方式写入新的 AOF 文件，然后再将 AOF 重写缓冲区（aof_rewrite_buf_blocks）的增量命令以 AOF 方式写入到文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。",-1),ys=t(`<div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code># 开启：在 redis 4 刚引入时，默认是关闭混合持久化的，但是在 redis 5 中默认已经打开了。
aof-use-rdb-preamble yes
# 关闭
aof-use-rdb-preamble no
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>优点：结合 RDB 和 AOF 的优点, 更快的重写和恢复。</p><p>缺点：AOF 文件里面的 RDB 部分不再是 AOF 格式，可读性差。</p><h2 id="缓存更新策略" tabindex="-1"><a class="header-anchor" href="#缓存更新策略"><span>缓存更新策略</span></a></h2><table><thead><tr><th></th><th>内存淘汰</th><th>超时剔除</th><th>主动更新</th></tr></thead><tbody><tr><td>描述</td><td>利用Redis内存淘汰机制，当内存不足时自动淘汰部分数据</td><td>给缓存数据添加TTL时间，到期后自动删除缓存，下次查询时更新缓存。</td><td>编写业务逻辑，在修改数据库的同时，更新缓存</td></tr><tr><td>一致性</td><td>差</td><td>一般</td><td>好</td></tr><tr><td>维护成本</td><td>无</td><td>低</td><td>高</td></tr></tbody></table><p><mark>主动更新策略</mark></p><p>❓删除缓存还是更新缓存？</p><ul><li>更新缓存：每次更新数据库时都更新缓存，可能产生多次更新缓存，但期间没人来查询缓存，产生无效写较多。❌</li><li>删除缓存：更新数据库时，让缓存失效，查询时再更新缓存。✔️</li></ul><p>❓先操作缓存还是先操作数据库？</p>`,9),fs=s("figure",null,[s("img",{src:"http://images.xyzzs.top/image/image-20230125110532941.png_char",alt:"image-20230125110532941",tabindex:"0",loading:"lazy"}),s("figcaption",null,"image-20230125110532941")],-1),zs=s("figure",null,[s("img",{src:"http://images.xyzzs.top/image/image-20230125111321967.png_char",alt:"image-20230125111321967",tabindex:"0",loading:"lazy"}),s("figcaption",null,"image-20230125111321967")],-1),xs=t(`<p>根据业务场景选择最佳实践方案：</p><ol><li>低一致性需求：使用Redis自带的内存淘汰机制。</li><li>高一致性需求：主动更新，并以超时剔除作为兜底方案。 <ul><li>读操作 <ul><li>缓存命中则直接返回</li><li>缓存未命中则查询数据库，并写入缓存，设定超时时间</li></ul></li><li>写操作 <ul><li>先写数据库，然后再删除缓存</li><li>必要时，确保数据库与缓冲操作的原子性</li></ul></li></ul></li></ol><h2 id="内存策略" tabindex="-1"><a class="header-anchor" href="#内存策略"><span>内存策略</span></a></h2><h3 id="过期策略" tabindex="-1"><a class="header-anchor" href="#过期策略"><span>过期策略</span></a></h3><p>🤔 思考：Redis如何知道一个key是否过期呢？如果TTL到期后是否立即删除呢？</p><p>Redis本身是一个典型的key-value内存存储数据库，因此所有的key、value都保存在Dict结构中。不过在其database结构体中，有两个Dict：一个用来记录key-value；另一个用来记录key-TTL。</p><div class="language-c line-numbers-mode" data-ext="c" data-title="c"><pre class="language-c"><code><span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token class-name">redisDb</span> <span class="token punctuation">{</span>
    dict <span class="token operator">*</span>dict<span class="token punctuation">;</span>		<span class="token comment">//存放所有key及value的地方</span>
    dict <span class="token operator">*</span>expires<span class="token punctuation">;</span>	<span class="token comment">//存放每一个key及TTL，只包含设置了TTL的key</span>
    dict <span class="token operator">*</span>blocking_keys<span class="token punctuation">;</span>
    dict <span class="token operator">*</span>read_keys<span class="token punctuation">;</span>
    dict <span class="token operator">*</span>watched_keys<span class="token punctuation">;</span>
    <span class="token keyword">int</span> id<span class="token punctuation">;</span>
    <span class="token keyword">long</span> <span class="token keyword">long</span> avg_ttl<span class="token punctuation">;</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">long</span> expires_cursor<span class="token punctuation">;</span>
<span class="token punctuation">}</span> redisDb<span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="http://images.xyzzs.top/image/image-20230127150342143.png_char" alt="image-20230127150342143" tabindex="0" loading="lazy"><figcaption>image-20230127150342143</figcaption></figure>`,8),Ss=s("p",null,"顾名思义并不是TTL到期后马上删除，而是在访问一个key时，检查该key的存货时间，如果已经过期才执行删除。",-1),Rs=s("p",null,[s("mark",null,"周期删除"),e("：定期抽样部分key，判断是否过期，如果过期则删除")],-1),Ls=s("p",null,"即通过一个定时任务，周期性的抽样部分过期的key，然后执行删除。执行周期分为两种：",-1),Os=s("ul",null,[s("li",null,"Redis会设置一个定时任务serverCorn()，按照server.hz频率来执行过期key，模式为SLOW"),s("li",null,"Redis的每个事件循环前会调用beforeSleep()函数，执行过期key清理，模式为FAST")],-1),Ds=s("strong",null,"SLOW模式规则",-1),Ts=s("p",null,"② 执行清理耗时不超过一次执行周期的25%",-1),ws=s("p",null,"③ 逐个遍历db，逐个遍历db中的bucket，抽取20个key判断是否过期",-1),Es=s("p",null,"④ 如果没打到时间上限（25ms）并且过期key比例不大于10%，再进行一次抽样，否则结束。",-1),Ns=s("strong",null,"FAST模式",-1),Is=t(`<p>② 执行清理耗时不超过1ms</p><p>③ 逐个遍历db，逐个遍历db中的bucket，抽取20个key判断是否过期</p><p>④ 如果没达到时间上限（1ms），并且过期key比例大于10%，再进行一次抽样，否则结束。</p><h3 id="淘汰策略" tabindex="-1"><a class="header-anchor" href="#淘汰策略"><span>淘汰策略</span></a></h3><p>内存淘汰：就是当Redis内存使用达到设置的阈值时，Redis主动挑选部分key删除以释放更多内存。</p><p>Redis会在处理客户端命令的方法processCommand()中尝试做内存淘汰（即执行处理命令时）</p><p><mark>8种淘汰策略</mark>，默认的策略为noeviction</p><div class="language-c line-numbers-mode" data-ext="c" data-title="c"><pre class="language-c"><code>noeviction：不会淘汰任何数据，当使用的内存空间超过 maxmemory 值时，再有写请求来时返回错误。
<span class="token keyword">volatile</span><span class="token operator">-</span>ttl：针对设置了过期时间的key，比较key的剩余TTL值，越小越先被淘汰
<span class="token keyword">volatile</span><span class="token operator">-</span>random：对设置了TTL的key，随机进行淘汰。也就是从db<span class="token operator">&gt;</span>expires中随机挑选
allkeys<span class="token operator">-</span>random：对全体key，随机进行淘汰。也就是从db<span class="token operator">&gt;</span>dict中随机挑选
<span class="token keyword">volatile</span><span class="token operator">-</span>lru，对设置了TTL的key，使用lru算法进行淘汰。
allkeys<span class="token operator">-</span>lru，对全体key，使用lru算法进行淘汰。
<span class="token keyword">volatile</span><span class="token operator">-</span>lfu，对设置了TTL的key，使用lfu算法进行淘汰。
allkeys<span class="token operator">-</span>lfu，对全体key，使用lfu算法进行淘汰。

<span class="token comment">/* 前缀为volatile-和allkeys-的区别在于二者选择要清除的键时的字典不同:
volatile - 前缀的策略代表从redisDb中的 expire 字典中选择键进行清除；
allkeys  - 前缀的策略代表从redisDb中的 dict 字典中选择键进行清除。 */</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,8),As=t(`<div class="language-c line-numbers-mode" data-ext="c" data-title="c"><pre class="language-c"><code><span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token class-name">redisObject</span> <span class="token punctuation">{</span>
    <span class="token keyword">unsigned</span> type<span class="token punctuation">;</span>
    <span class="token keyword">unsigned</span> encoding<span class="token punctuation">;</span>
    <span class="token comment">//LRU:以秒为单位记录最近一次访问时间，长度24bit</span>
    <span class="token comment">//LFU:高16位以分钟为单位记录最近一次访问时间，低8位记录逻辑访问次数</span>
    <span class="token keyword">unsigned</span> lru<span class="token punctuation">;</span>
    <span class="token keyword">int</span> refcount<span class="token punctuation">;</span>
    <span class="token keyword">void</span> <span class="token operator">*</span>ptr<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>LFU的访问次数之所以叫做<strong>逻辑访问次数</strong>，是因为并不是每次key被访问都计算，而是通过运算：</p>`,2),Bs=s("li",null,"生成 0 ~ 1 之间的随机数R",-1),Fs=s("li",null,[e("计算 "),s("code",null,"1/(旧次数 + lfr_log_factor + 1)"),e("，记录为P，lfr_log_factor 默认为10")],-1),Zs=s("li",null,"如果 R < P，则计数器 + 1，且最大不超过 255",-1),qs=t('<p><mark>淘汰流程</mark></p><figure><img src="http://images.xyzzs.top/image/1665412912054-7642e6c0-e05a-4d59-bd17-647fddc2fe43.png_char" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><h2 id="缓存穿透、缓存击穿、缓存雪崩" tabindex="-1"><a class="header-anchor" href="#缓存穿透、缓存击穿、缓存雪崩"><span>缓存穿透、缓存击穿、缓存雪崩</span></a></h2><h3 id="缓存穿透" tabindex="-1"><a class="header-anchor" href="#缓存穿透"><span>缓存穿透</span></a></h3>',4),Cs=t('<p>解决方案 ：</p><ol><li>缓存空对象：建议设置有效期 <ul><li>优点：实现简单，维护方便</li><li>缺点：额外的内存消耗，可能缓存大量不必要数据</li></ul></li><li>布隆过滤器：判断不存在的，则一定不存在；判断存在的，大概率存在，但也有小概率不存在。 <ul><li>优点：内存占用较少，没有多余key</li><li>缺点：1.实现复杂；2.存在误判可能，还是可能会发生穿透</li></ul></li><li>做好数据的基础格式校验</li><li>加强用户权限校验</li><li>做好热点参数的限流</li></ol><h3 id="缓存击穿" tabindex="-1"><a class="header-anchor" href="#缓存击穿"><span>缓存击穿</span></a></h3><p>也称热点key问题</p><p>产生原因：一个被<strong>高并发访问</strong>并且<strong>缓存重建业务复杂</strong>的key突然失效了，瞬间给数据库带来巨大冲击。</p><p>解决方案：</p><ol><li><p>互斥锁：保证每个key只有一个线程去查询数据库，而其他线程为等待状态。</p><img src="http://images.xyzzs.top/image/image-20230125133155500.png_char" alt="image-20230125133155500" style="zoom:50%;"></li><li><p>逻辑过期：设置缓存永远不过期，通过字段判断缓存是否有效，若失效且在重建过程中，可暂时返回旧数据。</p></li></ol><table><thead><tr><th></th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>互斥锁</td><td>没有额外的内存消耗<br>保证一致性<br>实现简答</td><td>线程需要等待，性能受影响<br>可能有死锁风险</td></tr><tr><td>逻辑过期</td><td>线程无需等待，性能较好</td><td>不保证一致性<br>有额外内存消耗<br>实现复杂</td></tr></tbody></table><h3 id="缓存雪崩" tabindex="-1"><a class="header-anchor" href="#缓存雪崩"><span>缓存雪崩</span></a></h3>',9),Ps=t(`<p>解决方案：</p><ol><li>不同的key的TTL设置随机值</li><li>利用Redis集群提高服务的可用性</li><li>给缓存业务添加降级限流策略</li><li>给业务添加多级缓存</li></ol><h2 id="缓存-分布式" tabindex="-1"><a class="header-anchor" href="#缓存-分布式"><span>缓存-分布式</span></a></h2><h3 id="主从" tabindex="-1"><a class="header-anchor" href="#主从"><span>主从</span></a></h3><p><mark>搭建主从架构</mark>，非常简单（改配置文件 &gt; 启动 &gt;&gt; 建立联系）</p><ol><li><p>复制配置文件redis.conf。<code>cp redis.conf redis7001.conf</code></p></li><li><p>改端口。</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment"># 改为空闲端口</span>
port <span class="token number">7001</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>修改保护进程。</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment">#这里原来是NO的，把它改为YES，这样它就可以在后台进行运行了</span>
daemonize <span class="token function">yes</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>修改pidfile</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment">#这里原来是pidfile /var/run/redis_6379.pid，这里后面的名字改为什么无所谓的，只要能做区分即可。</span>
pidfile /var/run/redis_7001.pid
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>添加日志文件</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment"># 这里原来是logfile &quot;&quot;，可以加上日志的文件名，名字可以随便起，为了方便以后查看，直接 port.log</span>
logfile <span class="token number">7001</span>.log
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>修改dbfilename</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code>dbfilename dump7001.log
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div></li><li><p>建立主从关系</p><ol><li><p>永久建立，redis.conf配置项</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code>replicaof <span class="token operator">&lt;</span>masterip<span class="token operator">&gt;</span> <span class="token operator">&lt;</span>masterport<span class="token operator">&gt;</span>
replicaof localhost <span class="token number">7001</span>

<span class="token comment"># 从机只读模式默认是开启的：</span>
replica-read-only <span class="token function">yes</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>临时建立，命令行方式</p><p>⚠️注意：这个方法只能是暂时的，如果重启之后，他们又不是主从关系了，如果想永久变为主从关系，那就是第一种方法。</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment"># 以7001主机，7002从机为例</span>
--启动7001、7002
--连接7002
redis-cli <span class="token parameter variable">-h</span> localhost <span class="token parameter variable">-p</span> <span class="token number">7002</span>

-- 执行slaveof命令（slaveof IP port）
slaveof localhost <span class="token number">7001</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol></li><li><p>查看主从信息</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment"># 主机查看主从信息（先运行redis-cli）,role:master，表示是主机,role:slave，表示从机</span>
info replication
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>测试</p><ol><li>主机执行set，从机执行get</li><li>从机执行set，无法执行<code>(error) READONLY You can&#39;t write against a read only replica.</code></li></ol></li></ol><hr><p><mark>全量同步</mark></p><p>主从第一次同步是全量同步</p><figure><img src="http://images.xyzzs.top/image/image-20230124140019432.png_char" alt="image-20230124140019432" tabindex="0" loading="lazy"><figcaption>image-20230124140019432</figcaption></figure><p>master如何判断slave是不是第一次来同步数据？需要以下字段保证：</p>`,11),Hs=t('<p>因此slave做数据同步时，必须向master声明自己的replication id和offset，master才能判断到底需要同步哪些数据。</p><p><mark>增量同步</mark></p><figure><img src="http://images.xyzzs.top/image/image-20230124140112235.png_char" alt="image-20230124140112235" tabindex="0" loading="lazy"><figcaption>image-20230124140112235</figcaption></figure><img src="http://images.xyzzs.top/image/image-20230124135718216.png_char" alt="image-20230124135718216" style="zoom:50%;"><p>⚠️repl_baklog大小有上限，写满后覆盖最早的数据。如果slave断开时间过久，导致尚未备份的数据被覆盖，则无法基于log做增量同步，只能再次全量同步。</p><p>可以从以下几个方面来优化Redis主从集群（思路1：减少全量同步、思路2：优化全量同步性能）</p><ul><li><p>在master中配置repl-diskless-sync yes启用无磁盘复制，避免全量同步时的磁盘IO—要求网络带宽高</p></li><li><p>Redis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO</p></li><li><p>适当提高repl_baklog的大小，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步</p></li><li><p>限制一个master上的slave节点数量，如果实在是太多slave，则可以采用主-从-从链式结构，减少mater压力</p><figure><img src="http://images.xyzzs.top/image/image-20230124141221433.png_char" alt="image-20230124141221433" tabindex="0" loading="lazy"><figcaption>image-20230124141221433</figcaption></figure><p><mark>全量/增量同步小结</mark></p><ol><li>简述全量同步和增量同步区别？ <ul><li>全量同步：master将完整内存数据生成RDB，发送到slave。后续命令记录在repl_baklog，逐个发送给slave。</li><li>增量同步：slave提交自己的offset到master，master获取repl_baklog中从offset之后的命令给slave</li></ul></li><li>什么时候执行全量同步? <ul><li>slave节点第一次连接master节点时</li><li>slave节点断开时间太久，repl_baklog中的offset已经被覆盖时</li></ul></li><li>什么时候执行增量同步? <ul><li>slave节点断开又恢复，并且repl_baklog中能找到offset时</li></ul></li></ol></li></ul><h3 id="哨兵" tabindex="-1"><a class="header-anchor" href="#哨兵"><span>哨兵</span></a></h3><p>🤔slave节点宕机恢复后可以找master节点同步数据，那master节点岩机怎么办?</p><p><mark>作用和原理</mark></p><p>Redis提供了哨兵(Sentinel)机制来实现主从集群的自动故障恢复。哨兵的结构和作用如下:</p><img src="http://images.xyzzs.top/image/image-20230124144519132.png_char" alt="image-20230124144519132" style="zoom:50%;"><ul><li>监控：Sentinel会不断检查master和slave是否按预期工作</li><li>自动故障恢复：如果master故障，Sentinel会将一个slave提升为master。当故障实例恢复后也以新的master为主</li><li>通知：Sentinel充当Redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给Redis的客户端</li></ul><hr><p>主要流程：状态监控 &gt; 选举新master &gt; 实现故障自动转移</p>',15),Ms=s("p",null,"Sentinel基于心跳机制监测服务状态，每隔1秒向集群的每个实例发送ping命令:",-1),js=s("ul",null,[s("li",null,"主观下线: 如果某sentinel节点发现某实例未在规定时间响应，则认为该实例主观下线。"),s("li",null,"客观下线:若超过指定数量(quorum)的sentinel都认为该实例主观下线，则该实例客观下线。quorum值最好超过Sentinel实例数量的一半。")],-1),Gs=s("p",null,"一旦发现master故障，sentinel需要在salve中选择一个作为新的master，选择依据是这样的:",-1),Ys=s("ul",null,[s("li",null,"首先会判断slave节点与master节点新开时间长短，如果超过指定值 (down-after-miliseconds* 10) 则会排除该slave节点"),s("li",null,"然后判断slave节点的slave-priority值，越小优先级越高"),s("li",null,"如果是0则永不参与选举如果slave-prority一样，则判断slave节点的sffset值，越大说明数据越新，优先级越高"),s("li",null,"最后是判断slave节点的运行id大小，越小优先级越高")],-1),Js=s("p",null,"当选中了其中一个slave为新的master后(例如slave1)，故障的转移的步骤如下",-1),Qs=s("ul",null,[s("li",null,"sentinel给备选的slave1节点发送slaveof no one命令，让该节点成为master"),s("li",null,"sentinel给所有其它slave发送slaveof 192.168.150.1017002命令，让这些slave成为新master的从节点，开始从新的master上同步数据。"),s("li",null,"最后，sentinel将故障节点标记为slave，当故障节点恢复后会自动成为新的master的slave节点")],-1),Us=t('<h3 id="分片式集群" tabindex="-1"><a class="header-anchor" href="#分片式集群"><span>分片式集群</span></a></h3><p>主从和哨兵可以解决高可用、高并发读的问题。但是依然有两个问题没有解决，😭经典白雪？😭</p><ul><li>海量数据存储问题</li><li>高并发写的问题</li></ul><p>使用分片集群可以解决上述问题，分片集群特征</p><ul><li>集群中有多个master，每个master保存不同数据</li><li>每个master都可以有多个slave节点</li><li>master之间通过ping监测彼此健康状态</li><li>客户端请求可以访问集群任意节点，最终都会被转发到正确节点</li></ul><p>分片集群结构如下</p><figure><img src="http://images.xyzzs.top/image/image-20230124162755259.png_char" alt="image-20230124162755259" tabindex="0" loading="lazy"><figcaption>image-20230124162755259</figcaption></figure><p><mark>散列插槽</mark></p><p>Redis会把每一个master节点映射到0~16384个插槽（hash slot）上。</p><p>数据key不是与节点绑定，而是与插槽绑定。redis会根据key的有效部分计算插槽值，分两种情况：</p><ul><li>key中包含&quot;{}&quot;，且“{}”中至少包含1个字符，“{}”中的部分是有效部分</li><li>key中不包含“{}”，整个key都是有效部分</li></ul><p>例如: key是num，那么就根据num计算，如果是{itcast}num，则根据itcast计算。计算方式是利用CRC16算法得到一个hash值，然后对16384取余，得到的结果就是slot值。</p><p>❓如何将同一类数据固定的保存在同一个Redis实例？</p><ul><li>这一类数据使用相同的有效部分，例如key都以{typeid}为前缀</li></ul><p><mark>集群收缩</mark></p>',15),Ks=t(`<div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment"># 加入集群</span>
redis-cli <span class="token parameter variable">--cluster</span> add-node <span class="token operator">&lt;</span>新IP<span class="token operator">&gt;</span>:<span class="token operator">&lt;</span>新端口<span class="token operator">&gt;</span> <span class="token operator">&lt;</span>集群其一IP<span class="token operator">&gt;</span>:<span class="token operator">&lt;</span>集群其一端口<span class="token operator">&gt;</span>
		  --cluster-salve <span class="token comment">#默认是主节点，加上此参数则默认从节点</span>
		  --cluster-master-id <span class="token operator">&lt;</span>arg<span class="token operator">&gt;</span> <span class="token comment">#并指定主机id</span>

<span class="token comment"># 新增后，从集群节点分配插槽给当前实例</span>
redis-cli <span class="token parameter variable">--cluster</span> reshard <span class="token operator">&lt;</span>集群其一IP<span class="token operator">&gt;</span>:<span class="token operator">&lt;</span>集群其一端口<span class="token operator">&gt;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,1),Vs=s("p",null,[e("⚠️删除主节点之前，为了"),s("strong",null,"防止数据的丢失"),e("以及"),s("strong",null,"集群功能的正常"),e("，先应"),s("strong",null,"把主节点所分配的哈希槽转移到其他主节点"),e("上。在移动哈希槽时，要注意哈希槽从0开始计数，所以"),s("strong",null,"移动时要输入的数字比添加时少1"),e("。")],-1),Ws=t(`<div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment"># 1.转移主节点分配的哈希槽</span>
redis-cli <span class="token parameter variable">--cluster</span> reshard <span class="token operator">&lt;</span>集群其一IP<span class="token operator">&gt;</span>:<span class="token operator">&lt;</span>集群其一端口<span class="token operator">&gt;</span>

<span class="token comment"># 2.删除没有哈希槽的主节点</span>
redis-cli <span class="token parameter variable">--cluster</span> del-node <span class="token operator">&lt;</span>删除IP<span class="token operator">&gt;</span>:<span class="token operator">&lt;</span>删除端口<span class="token operator">&gt;</span> 删除的节点ID
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,1),Xs={start:"2"},$s=t(`<div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code>redis-cli <span class="token parameter variable">--cluster</span> del-node <span class="token operator">&lt;</span>删除IP<span class="token operator">&gt;</span>:<span class="token operator">&lt;</span>删除端口<span class="token operator">&gt;</span> 删除的节点ID
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><hr><p><mark>故障转移</mark></p>`,3),se=s("ol",null,[s("li",null,"首先是该实例与其它实例失去连接"),s("li",null,"然后是疑似宕机"),s("li",null,"最后是确定下线，自动提升一个slave为新的master")],-1),ee=s("code",null,"cluster failover",-1),ae=s("code",null,"cluster failover",-1),ne=s("img",{src:"http://images.xyzzs.top/image/image-20230124195548323.png_char",alt:"image-20230124195548323",style:{zoom:"50%"}},null,-1),ie=s("p",null,"手动的Failover支持三种不同模式：",-1),te=s("ul",null,[s("li",null,"缺省：默认的流程，如图1~6步"),s("li",null,"force：省略了对offset的一致性校验"),s("li",null,"takeover：直接执行第5步，忽略数据一致性、忽略master状态和其它master的意见")],-1),le=s("hr",null,null,-1),pe=s("p",null,[s("mark",null,"集群注意点")],-1),oe=t(`<p>如果你的诉求是，集群不完整的话，也需要对外提供服务，比如如下图，你也希望其它的小集群仍能对外提供服务，就需要将该参数设置为no ；这样的话，挂掉的那个小集群是不行了，但是其他的小集群仍然可以对外提供服务</p><img src="http://images.xyzzs.top/image/20200419224851565.png_char" alt="在这里插入图片描述" style="zoom:75%;"><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment"># 为了保证高可用性，建议将cluster-require-full-coverage设置no</span>
cluster-require-full-coverage no
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div>`,3),de=s("p",null,"集群节点之间会不断的互相Ping来确定集群中其它节点的状态。每次Ping携带的信息至少包括:",-1),ce=s("ul",null,[s("li",null,"插槽信息"),s("li",null,"集群状态信息")],-1),re=s("p",null,"集群中节点越多，集群状态信息数据量也越大，10个节点的相关信息可能达到1kb，此时每次集群互通需要的带宽会非常高。解决方法如下：",-1),ue=s("ol",null,[s("li",null,"避免大集群，集群节点数不要太多，最好少于1000，如果业务庞大，可拆分业务，建立多个集群。"),s("li",null,"避免在单个物理机中运行太多Redis实例"),s("li",null,"配置合适的cluster-node-timeout值，节点失效检测时间，默认 15000 ms")],-1),me=s("p",null,"使用相同的有效key，导致部分负担过重",-1),ge=s("p",null,"访问集群，需要做节点的选择、插槽的判断、读写的判断等等，势必会浪费一部分性能",-1),he=s("p",null,"多键操作是不被支持的",-1),ke=s("p",null,"多键的Redis事务是不被支持的。lua脚本不被支持。",-1),ve=t('<p>❗可以看到集群实现还是相对复杂的，要考虑的细节也很多；且单体Redis（主从Redis）已经能达到万级别的QPS（能满足大部分中小厂需求），并且也具备很强的高可用性。如果主从能满足业务需求的情况下，不建议搭建Redis集群。</p><h2 id="redis网络模型" tabindex="-1"><a class="header-anchor" href="#redis网络模型"><span>redis网络模型</span></a></h2><p>❓Redis到底是单线程还是多线程？</p><ul><li>如果仅仅考虑Redis核心业务部分（命令处理），那么是单线程</li><li>如果是整个Redis，那么是多线程</li></ul><p>在Redis版本迭代过程中，在两个重要的时间节点上引入了多线程支持：</p><p>🔷Redis v4：引入多线程异步处理一些耗时较长的任务，例如异步删除命令等</p><p>🔷Redis v6：在核心网络模型中引入多线，进一步提高对于多喝CPU的利用率</p><p>❓那么，Redis为什么要坚持使用单线程呢？</p><ol><li>Redis是纯内存操作（暂不考虑持久化），执行速度非常快，它的性能瓶颈是网络延迟而不是执行速度，因此多线程并不会带来明显的性能提升。</li><li>多线程会导致过多的上下文切换，带来不必要的开销</li><li>引入多线程会面临线程安全问题，必然采取线程锁等安全手段，实现复杂度增高，而且性能也会有所下降。</li></ol><p>Redis v6 版本中引入了多线程，目的是为了提高IO读写效率。因此在解析客户端命令、写响应结果时采用了多线程。核心的命令执行、IO多路复用模块依然是主线程执行。</p><figure><img src="http://images.xyzzs.top/image/image-20230127172621033.png_char" alt="image-20230127172621033" tabindex="0" loading="lazy"><figcaption>image-20230127172621033</figcaption></figure><ol><li>启动server Socket，将server Socket的FD进行注册，监听该FD，并对此FD绑定处理器—<code>连接应答处理器</code>，该处理器用于接收客户的请求，处理server socket的readable事件</li><li>Client Socket向service Socket发起请求，触发client Socket的readable事件，绑定处理器—<code>命令请求处理器</code><ol><li>首先给每一个客户端封装一个对应的的client；</li><li>然后将请求数据写入client.queryBuf，</li><li>再调用client.queryBuf中的数据，通过解析，转为Redis命令，放在一个数组中</li><li>把执行结果写出，尝试把结果写到client.buf缓存区，如果写不下，则写到client.reply，这是个链表，无上限</li><li>将待写出的客户端添加到一个队列，等待被写出</li></ol></li><li>遍历队列中的client，监听FD写事件，绑定写处理器—<code>命令回复处理器</code>，将命令结果返回客户端。</li></ol><h2 id="最佳实践" tabindex="-1"><a class="header-anchor" href="#最佳实践"><span>最佳实践</span></a></h2><h3 id="redis键值设计" tabindex="-1"><a class="header-anchor" href="#redis键值设计"><span>Redis键值设计</span></a></h3><h4 id="优雅的key结构" tabindex="-1"><a class="header-anchor" href="#优雅的key结构"><span>优雅的key结构</span></a></h4><p>Redis的key虽然可以自定义，但最好遵循以下规则约定：</p><ul><li>遵循基本规则：[业务名称]:[数据名]:[id]，例：登陆业务，保存用户信息：<code>login:user:1024</code></li><li>长度不超过44字节，embstr在小于44字节使用，采用连续空间，内存占用更晓</li><li>不包含特殊字符</li></ul><p>优点：①可读性强；②避免key冲突；③方便管理；</p><h4 id="拒绝bigkey" tabindex="-1"><a class="header-anchor" href="#拒绝bigkey"><span>拒绝bigkey</span></a></h4><p>bigkey通常以key的大小和key中成员的数量来综合判定，</p><ul><li><p>key本身的数据量过大：一个String类型的key，它的值为5MB。</p></li><li><p>key中成员数过多：图个人ZSet类型的key，它的成员数量为10000 个。</p></li><li><p>key中成员的数据量过大：一个Hash类型的key，它的成员数量虽然只有1000个，但这些成员的value总大小100MB</p><p>推荐值：①单个key的value小于10kb；②对于集合类型的key，建议元素数量小于1000</p></li></ul><p><mark>Bigkey的危害</mark></p><ul><li><p>网络阻塞</p><p>对bigkey执行读请求时，少量的QPS就可能导致带宽使用率被占满，导致Redis实例，乃至所在物理机变慢</p></li><li><p>数据倾斜</p><p>bigkey所在的Redis实例内存使用率远超其他实例，无法达到均衡</p></li><li><p>Redis阻塞</p><p>对元素较多的hash、list、zset等做运算会耗时较久，使主线程被阻塞</p></li><li><p>CPI压力</p><p>对bigkey的数据序列化和反序列化会导致CPU使用率飙升，印象Redis实例和本机其他应用</p></li></ul><p><mark>如何发现Bigkey</mark></p><ul><li><p>redis-cli-bigkeys</p><p>利用redis-cli提供的 --bigkey参数，遍历分析所有key，并返回key的整体统计信息与每个数据的top1的bigkey</p></li><li><p>scan扫描</p><p>自己编程，利用scan扫描Redis中的所有key，利用strlen，hlen等命令判断key的长度</p></li><li><p>第三方工具</p><p>利用第三方工具，如<code>Redis-Rdb-Tools</code>分析RDB快照文件，全面分析内存使用情况</p></li><li><p>网络监控</p><p>自定义工具，监控进出Redis的网络数据，超出预警值时主动告警</p></li></ul><p><mark>如何删除Bigkey</mark></p><p>Bigkey内存占用较多，删除这样的key也需要耗费较长时间，导致Redis主线程阻塞，引发一些列问题。</p><ul><li><p>Redis V3 及以前版本</p><p>如何是集合类型，则遍历Bigkey的元素，先逐个删除子元素，最后删除Bigkey</p></li><li><p>Redis V4以后</p><p>4.0后提供异步删除命令：unlink</p></li></ul><h3 id="批处理" tabindex="-1"><a class="header-anchor" href="#批处理"><span>批处理</span></a></h3><h4 id="pipline" tabindex="-1"><a class="header-anchor" href="#pipline"><span>pipline</span></a></h4><p>批处理方案：</p><ol><li>原生的M操作</li><li>pipline批处理</li></ol><p>注意事项：</p><ul><li>批处理时不建议一次携带太多命令</li><li>pipline的多个命令之间不具备原子性</li></ul><h4 id="集群模式下的批处理" tabindex="-1"><a class="header-anchor" href="#集群模式下的批处理"><span>集群模式下的批处理</span></a></h4><p>如mset或pipline这样的批处理需要在一次请求中携带多条命令，而此时如果Redis是一个集群，那批处理命令的多个key必须落在一个插槽中，否则就会导致执行失败。</p><table><thead><tr><th></th><th>串行命令</th><th>串行slot</th><th>并行slot</th><th>hash_tag</th></tr></thead><tbody><tr><td>实现思路</td><td></td><td></td><td></td><td></td></tr><tr><td>耗时</td><td></td><td></td><td></td><td></td></tr><tr><td>优点</td><td></td><td></td><td></td><td></td></tr><tr><td>缺点</td><td></td><td></td><td></td><td></td></tr></tbody></table>',37);function be(_e,ye){const i=p("font"),o=p("ExternalLinkIcon"),d=p("marK");return r(),u("div",null,[g,s("p",null,[e("假设有一个intset，元素为{7,18,24}，因此采用的编码是"),a(i,{color:"blue"},{default:n(()=>[e("INTSET_ENC_INT16")]),_:1}),e("，则每个整数占2字节")]),h,s("p",null,[s("mark",null,[a(i,{color:"red",size:"6"},{default:n(()=>[e("渐进式rehash")]),_:1})])]),l(" 背这六大步骤 "),k,s("ol",null,[v,b,_,s("li",null,[a(i,{color:"Orchid"},{default:n(()=>[e("每次执行新增、查询、修改、删除操作时，都检查一下dict.rehashidx是否大于-1，如果是则将dict.ht[0].table[rehashidx]的entry链表rehash到dict[1]并将rehash++。直至dict.ht[0]中的所有数据rehash到dict.ht[1]。")]),_:1}),e("在rehash过程中，新增操作，则直接写入ht[1]，查询、修改和删除则会在dict[0]和dict[1]依次查找并执行。这样可以确保ht[0]的数据只减不增，随着rehash最终为空")]),y,f]),z,s("ul",null,[s("li",null,[e("previous_entry_length: 前一节点的长度，占1个或5个字节；"),a(i,{color:"Orchid"},{default:n(()=>[e("用于倒序遍历")]),_:1}),x]),s("li",null,[e("encoding：编码属性，记录content的数据类型（字符串还是整数）以及长度，占用1个、2个或5个字；"),a(i,{color:"Orchid"},{default:n(()=>[e("用于正序遍历")]),_:1})]),S]),R,L,O,D,s("ul",null,[s("li",null,[T,s("table",null,[w,s("tbody",null,[s("tr",null,[s("td",null,[e("|00"),a(i,{color:"Orchid"},{default:n(()=>[e("pppppp|")]),_:1})]),E,N]),s("tr",null,[s("td",null,[e("|01"),a(i,{color:"Orchid"},{default:n(()=>[e("pppppp|qqqqqqqq|")]),_:1})]),I,A]),s("tr",null,[s("td",null,[e("|10000000"),a(i,{color:"Orchid"},{default:n(()=>[e("|qqqqqqqq|rrrrrrrr|ssssssss|tttttttt")]),_:1})]),B,F])])])]),Z]),q,C,P,H,s("p",null,[e("假设我们有N个"),a(i,{color:"Orchid"},{default:n(()=>[e("连续的，长度为250~253字节之间")]),_:1}),e("的entry，因此entry的previous_entry_length属性用1个字节即可表示。现在头节点插入一个数据大于254字节，导致第二个节点的previous_entry_length从1个字节升到5个字节，第二个导致第三个，依次类推；ZipList这种特殊情况下产生的连续多次空间扩展操作称为"),M,e("，新增、删除都可能导致连锁更新的发生。")]),j,s("ol",null,[s("li",null,[a(i,{color:"red"},{default:n(()=>[e("list-max-ziplist-size配置")]),_:1}),G]),s("li",null,[a(i,{color:"red"},{default:n(()=>[e("QuickList压缩")]),_:1})])]),Y,s("ol",null,[s("li",null,[s("p",null,[e("其基本编码方式是"),J,e("，基于简单动态字符串 SDS 实现，"),a(i,{color:"Orchid"},{default:n(()=>[e("存储上限 512 MB ")]),_:1}),e("。")]),Q]),s("li",null,[s("p",null,[e("如果存储的"),a(i,{color:"Orchid"},{default:n(()=>[e("SDS长度小于44字节 ")]),_:1}),e("，则采用"),U,e("，此时 objecthead 和 SDS 是一段连续空间。申请内存只需要调用一次内存分配函数，效率更高。")]),K]),s("li",null,[s("p",null,[e("如果"),a(i,{color:"Orchid"},{default:n(()=>[e("存储的字符串是整数值")]),_:1}),e("，并且大小在LONG_MAX范围内，则会采用"),V,e("：直接将数据保存再RedisObject的ptr指针位置（刚好8字节），不再需要SDS。")]),W])]),X,s("ul",null,[$,s("li",null,[e("在3.2版本后，Redis统一采用"),a(i,{color:"Orchid"},{default:n(()=>[e("QuickList")]),_:1}),e("来实现List")])]),ss,s("ol",null,[s("li",null,[s("p",null,[e("为了保证查询效率和唯一性，Set采用"),a(i,{color:"red"},{default:n(()=>[e("HT编码（Dict）")]),_:1}),e("。Dict中的key用来存储元素，value统一为"),es])]),s("li",null,[s("p",null,[e("当存储的"),a(i,{color:"Orchid"},{default:n(()=>[e("所有数据都是整数")]),_:1}),e("，并且元素数量不超过"),a(i,{color:"Orchid"},{default:n(()=>[e("set-max-intset-entries")]),_:1}),e("时（默认512），Set会采用"),a(i,{color:"red"},{default:n(()=>[e("IntSet编码")]),_:1}),e("，节省内存；如果插入一个非整数，升级到dict类型")])])]),as,s("ul",null,[s("li",null,[e("SkipList：可排序，并且可以键值存储score和ele值，但"),a(i,{color:"Orchid"},{default:n(()=>[e("键不唯一")]),_:1})]),s("li",null,[e("HT（Dict）：可以键值存储，满足键需唯一，且查询效率高，但"),a(i,{color:"Orchid"},{default:n(()=>[e("不可排序")]),_:1})])]),ns,s("ol",null,[s("li",null,[a(i,{color:"red"},{default:n(()=>[e("采用 Dict + SkipList 存储")]),_:1}),is]),s("li",null,[s("p",null,[e("当"),a(i,{color:"Orchid"},{default:n(()=>[e("元素数量不多时")]),_:1}),e("，采用 HT 和 SkipList 的优势并不明显，而且"),ts,e("。因此zset还会"),a(i,{color:"red"},{default:n(()=>[e("采用ZipList结构")]),_:1}),e("存储来节省内存，不过需要同时满足以下两个条件：")]),ls,ps,os,ds,cs])]),rs,s("ul",null,[us,s("li",null,[ms,s("ol",null,[s("li",null,[s("p",null,[e("Ziplist中的元素数量超过了"),a(i,{color:"Orchid"},{default:n(()=>[e("hash-max-ziplist-entries")]),_:1}),e("（默认512）")])]),s("li",null,[s("p",null,[e("Ziplist中的任意entry大小超过了"),a(i,{color:"Orchid"},{default:n(()=>[e("hash-max-ziplist-value")]),_:1}),e("（默认64自己）")]),gs])])])]),hs,a(i,{color:"silver"},{default:n(()=>[e("tips：仅整理一些常用的命令，更多更详细最全命令参考：")]),_:1}),s("a",ks,[e("请查阅"),a(o)]),vs,s("p",null,[e("因为是记录命令，AOF文件会比RDB文件大的多。而且AOF会记录对同一个key的多次写操作，但只有最后一次写操作才有意义。通过"),a(i,{color:"Orchid"},{default:n(()=>[e("bgrewriteaof")]),_:1}),e("命令，可以让AOF文件执行重写功能，用最少的命令达到相同效果，既节省空间，也提升了恢复效率。")]),bs,s("p",null,[e("​ 整体格式为："),a(i,{color:"Orchid"},{default:n(()=>[e("RDB file + AOF tail")]),_:1})]),_s,a(i,{color:"Orchid"},{default:n(()=>[e("aof-use-rdb-preamble")]),_:1}),ys,s("ul",null,[s("li",null,[a(i,{color:"red"},{default:n(()=>[e("先删除缓存，后操作数据库")]),_:1}),e("：缓存删除后，更新数据库可能会比较耗时，并发环境下，其他线程此时进来可能无法感知到缓存的存在，直接查询数据库并返回。"),a(i,{color:"orchid"},{default:n(()=>[e("由于更新数据耗时长，发生概率较高。")]),_:1}),e("不推荐❌"),fs]),s("li",null,[a(i,{color:"red"},{default:n(()=>[e("先操作数据库，再删除缓存")]),_:1}),e("：在查询数据库后更新缓存前，第二个线程更新了数据库数据，导致数据库数据和缓存数据不一致。"),a(i,{color:"orchid"},{default:n(()=>[e("由于更新缓存速度很快，发生概率很小。")]),_:1}),e("推荐✔️"),zs])]),xs,a(d,null,{default:n(()=>[e("惰性删除")]),_:1}),e("：每次查找key时判断是否过期，如果过期则删除 "),Ss,Rs,Ls,Os,s("p",null,[Ds,e("——"),a(i,{color:"orchid"},{default:n(()=>[e("低频耗时")]),_:1})]),s("p",null,[e("① 执行频率受server.hz影响，默认10，即每秒执行10次，每个执行周期"),a(i,{color:"orchid"},{default:n(()=>[e("100ms")]),_:1}),e("。")]),Ts,ws,Es,s("p",null,[Ns,e("——"),a(i,{color:"orchid"},{default:n(()=>[e("高频不耗时")]),_:1})]),s("p",null,[e("① 执行频率受beforeSleep()调用频率影响，但两次FAST模式间隔"),a(i,{color:"orchid"},{default:n(()=>[e("不低于25ms")]),_:1})]),Is,s("p",null,[e("LRU(Least Recently Used)：最少"),a(i,{color:"orchid"},{default:n(()=>[e("最近")]),_:1}),e("使用。用当前时间减去最后一次访问时间，这个值越大，代表上次访问越久，则越优先淘汰。")]),s("p",null,[e("LFU(Least Frequently Used)：最少"),a(i,{color:"orchid"},{default:n(()=>[e("频率")]),_:1}),e("使用。统计每个key的访问频率，值越小，代表访问频率越低，则越优先淘汰。")]),As,s("ol",null,[Bs,Fs,Zs,s("li",null,[e("访问次数会随时间衰减，距离上一次访问时间间隔 lfr_decay_time 分钟（默认1），"),a(i,{color:"orchid"},{default:n(()=>[e("计数器 -1")]),_:1})])]),qs,s("p",null,[e("产生原因：指客户端请求的数据在"),a(i,{color:"orchid"},{default:n(()=>[e("缓存中和数据库中都不存在")]),_:1}),e("，这样缓存永不会生效，这些请求都会打到数据库。")]),Cs,s("p",null,[e("产生原因：在同一时段内"),a(i,{color:"orchid"},{default:n(()=>[e("大量的缓存key同时失效或者Redis服务宕机")]),_:1}),e("，导致大量请求到达数据库")]),Ps,s("ul",null,[s("li",null,[a(i,{color:"Orchid"},{default:n(()=>[e("Replication Id")]),_:1}),e("：简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid")]),s("li",null,[a(i,{color:"Orchid"},{default:n(()=>[e("offset")]),_:1}),e("：偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。如果slave的offset小于master的offset，说明slave数据落后于master，需要更新。")])]),Hs,a(i,{color:"orchid"},{default:n(()=>[e("服务状态监控")]),_:1}),Ms,js,a(i,{color:"orchid"},{default:n(()=>[e("选举新master")]),_:1}),Gs,Ys,a(i,{color:"orchid"},{default:n(()=>[e("如何实现故障转移")]),_:1}),Js,Qs,l(" <mark>搭建哨兵集群</mark> "),l(" <mark>RedisTemplate的哨兵模式</mark> "),Us,a(i,{color:"orchid"},{default:n(()=>[e("增加节点")]),_:1}),e("（包含主从节点添加方式）"),Ks,a(i,{color:"orchid"},{default:n(()=>[e("删除节点")]),_:1}),s("ol",null,[s("li",null,[a(i,{color:"red"},{default:n(()=>[e("删除主节点")]),_:1}),Vs])]),Ws,s("ol",Xs,[s("li",null,[a(i,{color:"red"},{default:n(()=>[e("删除从节点")]),_:1}),e("：若主节点没有分配插槽，也可直接删除该主节点")])]),$s,s("ul",null,[s("li",null,[a(i,{color:"orchid"},{default:n(()=>[e("自动转移")]),_:1}),e("：当集群中有一个master岩机，将会通过以下流程自动转移"),se]),s("li",null,[a(i,{color:"orchid"},{default:n(()=>[e("手动转移")]),_:1}),e("：一般适用于新机主动去替换旧主机"),s("p",null,[e("利用"),a(i,{color:"orchid"},{default:n(()=>[ee]),_:1}),e("命令可以手动让集群中的某个master宕机，切换到执行"),ae,e("命令的这个slave节点，实现无感知的数据迁移。其流程如下:")]),ne,ie,te])]),l(" <mark>搭建分片集群</mark> "),l(" <mark>RedisTemplate访问分片集群</mark> "),le,pe,s("ul",null,[s("li",null,[a(i,{color:"red"},{default:n(()=>[e("集群完整性问题")]),_:1}),a(i,{color:"orchid"},{default:n(()=>[e("cluster-require-full-coverage")]),_:1}),e("： 默认值 yes , 即需要集群完整性，方可对外提供服务"),oe]),s("li",null,[a(i,{color:"red"},{default:n(()=>[e("集群带宽问题")]),_:1}),de,ce,re,ue]),s("li",null,[a(i,{color:"red"},{default:n(()=>[e("数据倾斜问题")]),_:1}),me]),s("li",null,[a(i,{color:"red"},{default:n(()=>[e("客户端性能问题")]),_:1}),ge]),s("li",null,[a(i,{color:"red"},{default:n(()=>[e("命令的集群兼容性问题")]),_:1}),he]),s("li",null,[a(i,{color:"red"},{default:n(()=>[e("lua和事务问题")]),_:1}),ke])]),ve,l(`  

### 服务端配置优化

#### 内存配置

info memory

memory state

#### 命令及安全配置

秘钥登陆bug 

#### 慢查询配置

#### 持久化配置

`)])}const xe=c(m,[["render",be],["__file","index.html.vue"]]),Se=JSON.parse('{"path":"/redis/","title":"Redis导航栏","lang":"zh-CN","frontmatter":{"description":"Redis导航栏 数据结构与RedisObject ①简单动态字符串SDS Redis的底层是用C语言实现的，但C语言字符串存在很多问题： 获取字符串长度的需要通过运算 非字符串安全 不可修改 因此Redis构建了一种新的字符串结构，称为简单动态字符串（Simple Dynamic String）简称SDS。 其中SDS是一个结构体，源码如下： exa...","head":[["meta",{"property":"og:url","content":"https://vuepress-theme-hope-docs-demo.netlify.app/redis/"}],["meta",{"property":"og:site_name","content":"文档演示"}],["meta",{"property":"og:title","content":"Redis导航栏"}],["meta",{"property":"og:description","content":"Redis导航栏 数据结构与RedisObject ①简单动态字符串SDS Redis的底层是用C语言实现的，但C语言字符串存在很多问题： 获取字符串长度的需要通过运算 非字符串安全 不可修改 因此Redis构建了一种新的字符串结构，称为简单动态字符串（Simple Dynamic String）简称SDS。 其中SDS是一个结构体，源码如下： exa..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"http://images.xyzzs.top/image/image-20230122131601805.png_char"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-04-24T15:46:57.000Z"}],["meta",{"property":"article:author","content":"Mr.Hope"}],["meta",{"property":"article:modified_time","content":"2024-04-24T15:46:57.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Redis导航栏\\",\\"image\\":[\\"http://images.xyzzs.top/image/image-20230122131601805.png_char\\",\\"http://images.xyzzs.top/image/image-20230122133014915.png_char\\",\\"http://images.xyzzs.top/image/image-20230122135317734.png_char\\",\\"http://images.xyzzs.top/image/image-20230122142031230.png_char\\",\\"http://images.xyzzs.top/image/image-20230122143827719.png_char\\",\\"http://images.xyzzs.top/image/image-20230122151743360.png_char\\",\\"http://images.xyzzs.top/image/image-20230122165636300.png_char\\",\\"http://images.xyzzs.top/image/1672572686250-43cefc51-74ef-4f95-bac1-b02267383d4c.png_char\\",\\"http://images.xyzzs.top/image/image-20230122182941880.png_char\\",\\"http://images.xyzzs.top/image/1672573411313-8b9048b4-f2a9-403d-ae93-acfdd2491764.png_char\\",\\"http://images.xyzzs.top/image/1672573831777-b96f8724-444e-46ea-80e4-87486ced62c8.png_char\\",\\"http://images.xyzzs.top/image/1672574517911-630ccdf9-60ce-4185-bdfc-026981d4e31e.png_char\\",\\"http://images.xyzzs.top/image/image-20230122192805321.png_char\\",\\"http://images.xyzzs.top/image/image-20230122193828142.png_char\\",\\"http://images.xyzzs.top/image/image-20230122195421913.png_char\\",\\"http://images.xyzzs.top/image/image-20230122200438739.png_char\\",\\"http://images.xyzzs.top/image/image-20230122202833688.png_char\\",\\"http://images.xyzzs.top/image/image-20230122204056965.png_char\\",\\"http://images.xyzzs.top/image/image-20230123104322060.png_char\\",\\"http://images.xyzzs.top/image/image-20230123104423346.png_char\\",\\"http://images.xyzzs.top/image/image-20230123104535027.png_char\\",\\"http://images.xyzzs.top/image/image-20230123105908327.png_char\\",\\"http://images.xyzzs.top/image/image-20230123122029937.png_char\\",\\"http://images.xyzzs.top/image/image-20230123125355831.png_char\\",\\"http://images.xyzzs.top/image/image-20230123130324355.png_char_char\\",\\"http://images.xyzzs.top/image/image-20230123135653225.png_char_char\\",\\"http://images.xyzzs.top/image/image-20230123142800925.png_char\\",\\"http://images.xyzzs.top/image/image-20230123142606904.png_char\\",\\"http://images.xyzzs.top/image/image-20230123205540797.png_char\\",\\"http://images.xyzzs.top/image/image-20230123213045653.png_char\\",\\"http://images.xyzzs.top/image/image-20230125110532941.png_char\\",\\"http://images.xyzzs.top/image/image-20230125111321967.png_char\\",\\"http://images.xyzzs.top/image/image-20230127150342143.png_char\\",\\"http://images.xyzzs.top/image/1665412912054-7642e6c0-e05a-4d59-bd17-647fddc2fe43.png_char\\",\\"http://images.xyzzs.top/image/image-20230124140019432.png_char\\",\\"http://images.xyzzs.top/image/image-20230124140112235.png_char\\",\\"http://images.xyzzs.top/image/image-20230124141221433.png_char\\",\\"http://images.xyzzs.top/image/image-20230124162755259.png_char\\",\\"http://images.xyzzs.top/image/image-20230127172621033.png_char\\"],\\"dateModified\\":\\"2024-04-24T15:46:57.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Mr.Hope\\",\\"url\\":\\"https://mister-hope.com\\"}]}"]]},"headers":[{"level":2,"title":"数据结构与RedisObject","slug":"数据结构与redisobject","link":"#数据结构与redisobject","children":[{"level":3,"title":"①简单动态字符串SDS","slug":"_1简单动态字符串sds","link":"#_1简单动态字符串sds","children":[]},{"level":3,"title":"②IntSet—整数数组","slug":"_2intset—整数数组","link":"#_2intset—整数数组","children":[]},{"level":3,"title":"③Dict—字典","slug":"_3dict—字典","link":"#_3dict—字典","children":[]},{"level":3,"title":"④ZipList","slug":"_4ziplist","link":"#_4ziplist","children":[]},{"level":3,"title":"⑤QuickList","slug":"_5quicklist","link":"#_5quicklist","children":[]},{"level":3,"title":"⑥SkipList","slug":"_6skiplist","link":"#_6skiplist","children":[]},{"level":3,"title":"RedisObject","slug":"redisobject","link":"#redisobject","children":[]}]},{"level":2,"title":"五种常用数据类型","slug":"五种常用数据类型","link":"#五种常用数据类型","children":[{"level":3,"title":"底层实现——String","slug":"底层实现——string","link":"#底层实现——string","children":[]},{"level":3,"title":"底层实现——List","slug":"底层实现——list","link":"#底层实现——list","children":[]},{"level":3,"title":"底层实现——Set","slug":"底层实现——set","link":"#底层实现——set","children":[]},{"level":3,"title":"底层实现——ZSet","slug":"底层实现——zset","link":"#底层实现——zset","children":[]},{"level":3,"title":"底层实现——Hash","slug":"底层实现——hash","link":"#底层实现——hash","children":[]},{"level":3,"title":"使用场景","slug":"使用场景","link":"#使用场景","children":[]},{"level":3,"title":"常见命令操作","slug":"常见命令操作","link":"#常见命令操作","children":[]}]},{"level":2,"title":"持久策略","slug":"持久策略","link":"#持久策略","children":[{"level":3,"title":"RDB","slug":"rdb","link":"#rdb","children":[]},{"level":3,"title":"AOF","slug":"aof","link":"#aof","children":[]},{"level":3,"title":"混合持久化","slug":"混合持久化","link":"#混合持久化","children":[]}]},{"level":2,"title":"缓存更新策略","slug":"缓存更新策略","link":"#缓存更新策略","children":[]},{"level":2,"title":"内存策略","slug":"内存策略","link":"#内存策略","children":[{"level":3,"title":"过期策略","slug":"过期策略","link":"#过期策略","children":[]},{"level":3,"title":"淘汰策略","slug":"淘汰策略","link":"#淘汰策略","children":[]}]},{"level":2,"title":"缓存穿透、缓存击穿、缓存雪崩","slug":"缓存穿透、缓存击穿、缓存雪崩","link":"#缓存穿透、缓存击穿、缓存雪崩","children":[{"level":3,"title":"缓存穿透","slug":"缓存穿透","link":"#缓存穿透","children":[]},{"level":3,"title":"缓存击穿","slug":"缓存击穿","link":"#缓存击穿","children":[]},{"level":3,"title":"缓存雪崩","slug":"缓存雪崩","link":"#缓存雪崩","children":[]}]},{"level":2,"title":"缓存-分布式","slug":"缓存-分布式","link":"#缓存-分布式","children":[{"level":3,"title":"主从","slug":"主从","link":"#主从","children":[]},{"level":3,"title":"哨兵","slug":"哨兵","link":"#哨兵","children":[]},{"level":3,"title":"分片式集群","slug":"分片式集群","link":"#分片式集群","children":[]}]},{"level":2,"title":"redis网络模型","slug":"redis网络模型","link":"#redis网络模型","children":[]},{"level":2,"title":"最佳实践","slug":"最佳实践","link":"#最佳实践","children":[{"level":3,"title":"Redis键值设计","slug":"redis键值设计","link":"#redis键值设计","children":[]},{"level":3,"title":"批处理","slug":"批处理","link":"#批处理","children":[]}]}],"git":{"createdTime":1713973617000,"updatedTime":1713973617000,"contributors":[{"name":"jossezs","email":"zzss5224@163.com","commits":1}]},"readingTime":{"minutes":51.01,"words":15303},"filePathRelative":"redis/README.md","localizedDate":"2024年4月24日","autoDesc":true}');export{xe as comp,Se as data};
