# 计算机网络概述导航栏

概念、组成、功能和分类

标准化工作及相关组织

速率相关的性能指标

时延、时延带宽积、RTT和利用率

## 体系结构和参考模型

为了使得多种设备能通过网络相互通信，和为了解决各种不同设备在网络互联中的兼容性问题，国际标准化组织制定了开放式系统互联通信参考模型（Open System Interconnection Reference Model），也就是 OSI 网络模型，该模型主要有 7 层，分别是应用层、表示层、会话层、传输层、网络层、数据链路层以及物理层。

每一层负责的职能都不同，如下：

- 应用层，负责给应用程序提供统一的接口；
- 表示层，负责把数据转换成兼容另一个系统能识别的格式；
- 会话层，负责建立、管理和终止表示层实体之间的通信会话；
- 传输层，负责端到端的数据传输；
- 网络层，负责数据的路由、转发、分片；
- 数据链路层，负责数据的封帧和差错检测，以及 MAC 寻址；
- 物理层，负责在物理网络中传输数据帧；

由于 OSI 模型实在太复杂，提出的也只是概念理论上的分层，并没有提供具体的实现方案。

事实上，我们比较常见，也比较实用的是四层模型，即 TCP/IP 网络模型，Linux 系统正是按照这套网络模型来实现网络协议栈的。

TCP/IP 网络模型共有 4 层，分别是应用层、传输层、网络层和网络接口层，每一层负责的职能如下：

- 应用层，负责向用户提供一组应用程序，比如 HTTP、DNS、FTP 等;
- 传输层，负责端到端的通信，比如 TCP、UDP 等；
- 网络层，负责网络包的封装、分片、路由、转发，比如 IP、ICMP 等；
- 网络接口层，负责网络包在物理网络中的传输，比如网络包的封帧、 MAC 寻址、差错检测，以及通过网卡传输网络帧等；

TCP/IP 网络模型相比 OSI 网络模型简化了不少，也更加易记，它们之间的关系如下图：

![image-20230131130953345](http://images.xyzzs.top/image/image-20230131130953345.png_char)

## 物理层

### 码元、波特、速率、带宽

### 奈氏准则&香农定理

### 编码和调制

### 物理层传输介质

### 物理层设备



## 数据链路层

### 差错控制

### 信道



## 网络层

生活中去旅游，飞机票和地铁票都是去往特定的地点的，每张票只能够在某一限定区间内移动，此处的「区间内」就如同通信网络中数据链路。

在区间内移动相当于数据链路层，充当区间内两个节点传输的功能，区间内的出发点好比源 MAC 地址，目标地点好比目的 MAC 地址。

整个旅游行程表就相当于网络层，充当远程定位的功能，行程的开始好比源 IP，行程的终点好比目的 IP 地址。

如果只有行程表而没有车票，就无法搭乘交通工具到达目的地。相反，如果除了车票而没有行程表，恐怕也很难到达目的地。因为不知道该坐什么车，也不知道该在哪里换乘。 

其实，在网络中数据包传输中也是如此，**源IP地址和目标IP地址在传输过程中是不会变化的（前提：没有使用 NAT 网络），只有源 MAC 地址和目标 MAC 一直在变化。**

### IP的分类

<img src="http://images.xyzzs.top/image/image-20230130162122288.png_char_char" alt="image-20230130162122288" style="zoom:67%;" />

对于 A、B、C 类主要分为两个部分，分别是**网络号和主机号**。

而 D 类和 E 类地址是没有主机号的，所以不可用于主机 IP，D 类常被用于**多播**，E 类是预留的分类，暂时未使用。

<img src="http://images.xyzzs.top/image/image-20230130160551696.png_char" alt="image-20230130160551696" style="zoom:80%;" />

<img src="http://images.xyzzs.top/image/image-20230130160738664.png_char" alt="image-20230130160738664" style="zoom:80%;" />

在 IP 地址中，有两个 IP 是特殊的，分别是主机号全为 1 和 全为 0 地址。因此，在分配过程中，应该去掉这两种情况。

- 主机号全为 1 指定某个网络下的所有主机，用于广播
- 主机号全为 0 指定某个网络

![image-20230130162345537](http://images.xyzzs.top/image/image-20230130162345537.png_char)

优点：简单明了、选路（基于网络地址）简单

不管是路由器还是主机解析到一个 IP 地址时候，我们判断其 IP 地址的首位是否为 0，为 0 则为 A 类地址，那么就能很快的找出网络地址和主机地址。

<img src="http://images.xyzzs.top/image/image-20230130161138008.png_char" alt="image-20230130161138008" style="zoom: 50%;" />

缺点

1. **同一网络下没有地址层次**，比如一个公司里用了 B 类地址，但是可能需要根据生产环境、测试环境、开发环境来划分地址层次，而这种 IP 分类是没有地址层次划分的功能，所以这就**缺少地址的灵活性**。
2. A、B、C类有个尴尬处境，就是**不能很好的与现实网络匹配**。
   - C 类地址能包含的最大主机数量实在太少了，只有 254 个。
   - 而 B 类地址能包含的最大主机数量又太多了，6 万多台机器放在一个网络下面，一般的企业基本达不到这个规模，闲着的地址就是浪费。

这两个缺点，都可以在 CIDR 无分类地址解决。

### 无分类地址 CIDR

正因为 IP 分类存在许多缺点，所以后面提出了无分类地址的方案，即 `CIDR`。

这种方式不再有分类地址的概念，32 比特的 IP 地址被划分为两部分，前面是**网络号**，后面是**主机号**。

表示形式 `a.b.c.d/x`，其中 `/x` 表示前 x 位属于**网络号**， x 的范围是 `0 ~ 32`，这就使得 IP 地址更加具有灵活性。

比如 10.100.122.2/24，这种地址表示形式就是 CIDR，/24 表示前 24 位是网络号，剩余的 8 位是主机号。

<img src="http://images.xyzzs.top/image/image-20230130162526692.png_char" alt="image-20230130162526692" style="zoom:80%;" />

还有另一种划分网络号与主机号形式，那就是**子网掩码**，掩码的意思就是掩盖掉主机号，剩余的就是网络号。

**将子网掩码和 IP 地址按位计算 AND，就可得到网络号**

![](http://images.xyzzs.top/image/image-20230130162627325.png_char_char)

:question:为什么要分离网络号和主机号？

路由器寻址工作中，也就是通过这样的方式来找到对应的网络号的，进而把数据包转发给对应的网络内

<img src="http://images.xyzzs.top/image/image-20230130162928688.png_char" alt="image-20230130162928688" style="zoom:80%;" />

:question:怎么进行子网划分？

在上面我们知道可以通过子网掩码划分出网络号和主机号，那实际上子网掩码还有一个作用，那就是**划分子网**。

**子网划分实际上是将主机地址分为两个部分：子网网络地址和子网主机地址**。形式如下：

![image-20230130163116398](http://images.xyzzs.top/image/image-20230130163116398.png_char)



由于子网网络地址被划分成 2 bit，那么子网地址就有 4 个，分别是 00、01、10、11，具体划分如下图：

<img src="http://images.xyzzs.top/image/image-20230130163643985.png_char" alt="image-20230130163643985" style="zoom: 67%;" />

划分后的 4 个子网如下表格：

![image-20230130163515161](http://images.xyzzs.top/image/image-20230130163515161.png_char)



### 公有 IP 地址与私有 IP 地址

私有 IP 地址通常是内部的 IT 人员管理，公有 IP 地址是由 `ICANN` 组织管理，中文叫「互联网名称与数字地址分配机构」。IANA 是 ICANN 的其中一个机构，它负责分配互联网 IP 地址，是按州的方式层层分配。其中，在中国是由 CNNIC 的机构进行管理，它是中国国内唯一指定的全局 IP 地址管理的组织。

<img src="http://images.xyzzs.top/image/image-20230130164235208.png_char" alt="image-20230130164235208" style="zoom:80%;" />



### IP 地址与路由控制

IP地址的**网络地址**这一部分是用于进行**路由控制**。

路由控制表中记录着网络地址与下一步应该发送至路由器的地址。在主机和路由器上都会有各自的路由器控制表。

在发送 IP 包时，首先要确定 IP 包首部中的目标地址，再从路由控制表中找到与该地址具有**相同网络地址**的记录，根据该记录将 IP 包转发给相应的下一个路由器。<font color=orchid>如果路由控制表中存在多条相同网络地址的记录，就选择相同位数最多的网络地址，也就是**最长匹配**</font>。

![image-20230130164852872](http://images.xyzzs.top/image/image-20230130164852872.png_char)

1. 主机 A 要发送一个 IP 包，其源地址是 `10.1.1.30` 和目标地址是 `10.1.2.10`，由于没有在主机 A 的路由表找到与目标地址 `10.1.2.10` 相同的网络地址，于是包被转发到默认路由（路由器 `1` ）
2. 路由器 `1` 收到 IP 包后，也在路由器 `1` 的<font color=orchid>路由表匹配与目标地址相同的网络地址记录</font>，发现匹配到了，于是就把 IP 数据包转发到了 `10.1.0.2` 这台路由器 `2`
3. 路由器 `2` 收到后，同样对比自身的路由表，发现匹配到了，于是把 IP 包从路由器 `2` 的 `10.1.2.1` 这个接口出去，最终经过交换机把 IP 数据包转发到了目标主机

### IP 分片与重组

每种数据链路的最大传输单元 `MTU` 都是不相同的，如 FDDI 数据链路 MTU 4352、以太网的 MTU 是 1500 字节等。

那么当 IP 数据包大小大于 MTU 时， IP 数据包就会被分片。

经过分片之后的 IP 数据报在被重组的时候，只能由目标主机进行，路由器是不会进行重组的。

假设发送方发送一个 4000 字节的大数据报，若要传输在以太网链路，则需要把数据报分片成 3 个小数据报进行传输，再交由接收方重组成大数据报。

在分片传输中，一旦某个分片丢失，则会造成整个 IP 数据报作废，所以 TCP 引入了 `MSS` 也就是在 TCP 层进行分片不由 IP 层分片，那么对于 UDP 我们尽量不要发送一个大于 `MTU` 的数据报文

### IP 协议相关技术

- DNS 

  **DNS 域名解析**，可以将域名网址自动转换为具体的 IP 地址。

  DNS 中的域名都是用**句点**来分隔的，比如 `www.server.com`，这里的句点代表了不同层次之间的**界限**。在域名中，**越靠右**的位置表示其层级**越高**。

  根域是在最顶层，它的下一层就是 com 顶级域，再下面是 server.com。所以域名的层级关系类似一个树状结构：

  ![image-20230130170837959](http://images.xyzzs.top/image/image-20230130170837959.png_char)

<mark>域名解析的工作流程</mark>

浏览器首先看一下自己的缓存里有没有，如果没有就向操作系统的缓存要，还没有就检查本机域名解析文件 `hosts`，如果还是没有，就会 DNS 服务器进行查询，查询的过程如下：

<img src="http://images.xyzzs.top/image/image-20230130171525898.png_char" alt="image-20230130171525898" style="zoom: 67%;" />

1. 客户端首先会发出一个 DNS 请求，问 www.server.com 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP/IP 设置中填写的 DNS 服务器地址）。
2. 本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 www.server.com，则它直接返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我  www.server.com 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。
3. 根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“www.server.com 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”
4. 本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 www.server.com  的 IP 地址吗？”
5. 顶级域名服务器说：“我给你负责 www.server.com 区域的权威 DNS 服务器的地址，你去问它应该能问到”。
6. 本地 DNS 于是转向问权威 DNS 服务器：“老三，www.server.com对应的IP是啥呀？” server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。
7. 权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。
8. 本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。

DNS 域名解析，整个过程就和我们日常生活中找人问路的过程类似，**只指路不带路**。

- ARP 与 RARP 协议

  ARP 如何知道对方 MAC 地址？

  - 主机会通过**广播发送 ARP 请求**，这个包中包含了想要知道的 MAC 地址的主机 IP 地址。
  - 当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包里的内容，如果 ARP 请求包中的目标 IP 地址与自己的 IP 地址一致，那么这个设备就将自己的 MAC 地址塞入 **ARP 响应包**返回给主机。

  操作系统通常会把第一次通过 ARP 获取的 MAC 地址缓存起来，以便下次直接从缓存中找到对应 IP 地址的 MAC 地址。

  ![image-20230130172023290](http://images.xyzzs.top/image/image-20230130172023290.png_char)

- DHCP 动态获取 IP 地址

  我们的电脑通常都是通过 DHCP 动态获取 IP 地址，大大省去了配 IP 信息繁琐的过程。

  

- NAT 网络地址转换

  ![image-20230130173122611](http://images.xyzzs.top/image/image-20230130173122611.png_char)

  图中有两个客户端 192.168.1.10 和 192.168.1.11 同时与服务器 183.232.231.172 进行通信，并且这两个客户端的本地端口都是 1025。

  此时，**两个私有 IP 地址都转换 IP 地址为公有地址 120.229.175.121，但是以不同的端口号作为区分。**

  于是，生成一个 NAPT 路由器的转换表，就可以正确地转换地址跟端口的组合，令客户端 A、B 能同时与服务器之间进行通信。



- ICMP 互联网控制报文协议

  `ICMP` 主要的功能包括：**确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。**

- IGMP 因特网组管理协议

  **IGMP 是因特网组管理协议，工作在主机（组播成员）和最后一跳路由之间**，如上图中的蓝色部分。

  - IGMP 报文向路由器申请加入和退出组播组，默认情况下路由器是不会转发组播包到连接中的主机，除非主机通过 IGMP 加入到组播组，主机申请加入到组播组时，路由器就会记录 IGMP 路由器表，路由器后续就会转发组播包到对应的主机了。
  - IGMP 报文采用 IP 封装，IP 头部的协议号为 2，而且 TTL 字段值通常为 1，因为 IGMP 是工作在主机与连接的路由器之间。

  <img src="http://images.xyzzs.top/image/image-20230130173549002.png_char" alt="image-20230130173549002" style="zoom:67%;" />





## 传输层

TCP 是**面向连接的、可靠的、基于字节流**的传输层通信协议。

![image-20230131090515110](http://images.xyzzs.top/image/image-20230131090515110.png_char)

- 面向连接：一定是<font color=orchid>一对一</font>才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；
- 可靠的：无论的网络链路中出现了怎样的链路变化，TCP 都可以<font color=orchid>保证一个报文一定能够到达接收端</font>；
- 字节流：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP  报文，如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。并且 TCP 报文是「有序的」，当「前一个」TCP  报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃。

### TCP 头部

<img src="http://images.xyzzs.top/image/image-20230131092651107.png_char" alt="image-20230131092651107" style="zoom: 67%;" />

**序列号**：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。**用来解决网络包乱序问题。**

**确认应答号**：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。**用来解决丢包的问题。**

**控制位：**

- *ACK*：该位为 `1` 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 `SYN` 包之外该位必须设置为 `1` 。
- *RST*：该位为 `1` 时，表示 TCP 连接中出现异常必须强制断开连接。
- *SYN*：该位为 `1` 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。
- *FIN*：该位为 `1` 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 `FIN` 位为 1 的 TCP 段。

### 三次握手与四次挥手

<mark>三次握手</mark>



<img src="http://images.xyzzs.top/image/image-20230131093428345.png_char" alt="image-20230131093428345" style="zoom:67%;" />

1. 一开始，客户端和服务端都处于 `CLOSE` 状态。先是服务端主动监听某个端口，处于 `LISTEN` 状态。
2. 客户端会随机初始化序号（`client_isn`），将此序号置于 TCP 首部的「序号」字段中，同时<font color=orchid>把 `SYN` 标志位置为 `1`</font>，表示 `SYN` 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，<font color=orchid>该报文不包含应用层数据</font>，之后客户端处于 `SYN-SENT` 状态。
3. 服务端收到客户端的 `SYN` 报文后，首先服务端也随机初始化自己的序号（`server_isn`），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 `client_isn + 1`, 接着<font color=orchid>把 `SYN` 和 `ACK` 标志位置为 `1`</font>。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 `SYN-RCVD` 状态。
4. 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部<font color=orchid> `ACK` 标志位置为 `1` </font>，其次「确认应答号」字段填入 `server_isn + 1` ，最后把报文发送给服务端，这次报文<font color=orchid>可以携带客户到服务端的数据</font>，之后客户端处于 `ESTABLISHED` 状态。
5. 服务端收到客户端的应答报文后，也进入 `ESTABLISHED` 状态。

:question:<font color=red>**为什么是三次握手？不是两次、四次？**</font>

简单来说，三次握手的**首要原因是为了防止旧的重复连接初始化造成混乱。**

我们考虑一个场景，客户端先发送了 SYN（seq = 90）报文，然后客户端宕机了，而且这个 SYN 报文还被网络阻塞了，服务端并没有收到，接着客户端重启后，又重新向服务端建立连接，发送了 SYN（seq = 100）报文（注意！不是重传 SYN，重传的 SYN 的序列号是一样的）。

<img src="http://images.xyzzs.top/image/image-20230131094620693.png_char" alt="image-20230131094620693" style="zoom:67%;" />

**如果是两次握手连接，就无法阻止历史连接**，那为什么 TCP 两次握手为什么无法阻止历史连接呢？

先直接说结论，主要是因为<font color=orchid>**在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费**</font>。

你想想，在两次握手的情况下，服务端在收到 SYN 报文后，就进入 ESTABLISHED  状态，意味着这时可以给对方发送数据，但是客户端此时还没有进入 ESTABLISHED  状态，假设这次是历史连接，客户端判断到此次连接为历史连接，那么就会回 RST 报文来断开连接，而服务端在第一次握手的时候就进入  ESTABLISHED 状态，所以它可以发送数据的，但是它并不知道这个是历史连接，它只有在收到 RST 报文后，才会断开连接。

![image-20230131095644080](http://images.xyzzs.top/image/image-20230131095644080.png_char)

可以看到，如果采用两次握手建立 TCP 连接的场景下，服务端在向客户端发送数据前，并没有阻止掉历史连接，导致服务端建立了一个历史连接，又白白发送了数据，妥妥地浪费了服务端的资源

*小结*

- 「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；
- 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。

<mark>四次挥手</mark>

TCP 断开连接是通过四次挥手方式。双方都可以主动断开连接，断开连接后主机中的「资源」将被释放，四次挥手的过程如下图：

<img src="http://images.xyzzs.top/image/image-20230131102315565.png_char" alt="image-20230131102315565" style="zoom:80%;" />

- 客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。
- 服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSE_WAIT` 状态。
- 客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态。
- 等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。
- 客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态
- 服务端收到了 `ACK` 应答报文后，就进入了 `CLOSE` 状态，至此服务端已经完成连接的关闭。
- 客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSE` 状态，至此客户端也完成连接的关闭。

:question:<font color=red>**为什么挥手需要四次**</font>

- 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。
- 服务端收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。

从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送，因此是需要四次挥手。

但是**在特定情况下，四次挥手是可以变成三次挥手的**。



### 重传

TCP 实现可靠传输的方式之一，是通过序列号与确认应答。在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。但在网络中，并不一定能顺利能正常的数据传输，万一数据在传输过程中丢失了呢？所以 TCP 针对数据包丢失的情况，会用**重传机制**解决。

<mark>超时重传</mark>

重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 `ACK` 确认应答报文，就会重发该数据。

TCP 会在以下两种情况发生超时重传：

- 数据包丢失
- 确认应答丢失

:question:超时时间应该设置为多少呢？

`RTT` （Round-Trip Time 往返时延）指的是**数据发送时刻到接收到确认的时刻的差值**，也就是包的往返时间。

超时重传时间是以 `RTO` （Retransmission Timeout 超时重传时间）表示。

<img src="http://images.xyzzs.top/image/image-20230131104847107.png_char_char" style="zoom:50%;" />

- 当超时时间 **RTO 较大**时，重发就慢，丢了老半天才重发，没有效率，性能差；
- 当超时时间 **RTO 较小**时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。

精确的测量超时时间 `RTO` 的值是非常重要的，这可让我们的重传机制更高效。根据上述的两种情况，我们可以得知，**超时重传时间 RTO 的值应该略大于报文往返  RTT 的值**。「报文往返 RTT 的值」是经常变化的，因为我们的网络也是时常变化的。也就因为「报文往返 RTT 的值」 是经常波动变化的，所以「超时重传时间 RTO 的值」应该是一个**动态变化的值**。大致算法是：首次计算出RTO后，后续计算RTO都会用上次计算的RTO值。

如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是**超时间隔加倍。**也就是**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。**

超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？于是就可以用「快速重传」机制来解决超时重发的时间等待

<mark>快速重传</mark>

**不以时间为驱动，而是以数据驱动重传**。![image-20230131105814098](http://images.xyzzs.top/image/image-20230131105814098.png_char)

在上图，发送方发出了 1，2，3，4，5 份数据：

- 第一份 Seq1 先送到了，于是就 Ack 回 2；
- 结果 Seq2 因为某些原因没收到，Seq3 到达了，于是还是 Ack 回 2；
- 后面的 Seq4 和 Seq5 都到了，但还是 Ack 回 2，因为 Seq2 还是没有收到；
- **发送端收到了三个 Ack = 2 的确认，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2。**
- 最后，收到了 Seq2，此时因为 Seq3，Seq4，Seq5 都收到了，于是 Ack 回 6 。

所以，快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。

快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题。就是**重传的时候，是重传一个，还是重传所有的问题。**为了解决不知道该重传哪些 TCP 报文，于是就有 `SACK` 方法。

<mark>SACK</mark>

还有一种实现重传机制的方式叫：`SACK`（ Selective Acknowledgment）， **选择性确认**。

这种方式需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将已收到的数据的信息发送给「发送方」**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。

如下图，发送方收到了三次同样的 ACK 确认报文，于是就会触发快速重发机制，通过 `SACK` 信息发现只有 `200~299` 这段数据丢失，则重发时，就只选择了这个 TCP 段进行重复。

<img src="http://images.xyzzs.top/image/image-20230131110453077.png_char" alt="image-20230131110453077" style="zoom: 67%;" />

如果要支持 `SACK`，必须双方都要支持。在 Linux 下，可以通过 `net.ipv4.tcp_sack` 参数打开这个功能（Linux 2.4 后默认打开）

<mark>Duplicate SACK</mark>

又称 `D-SACK`，其主要**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。**

为什么会重复发送：返回的确认号ACK 丢包；网络延时

### 滑动窗口、流量控制

我们都知道 TCP 是每发送一个数据，都要进行一次确认应答。当上一个数据包收到了应答了， 再发送下一个。这个模式就有点像我和你面对面聊天，你一句我一句。但这种方式的缺点是<font color=orchid>往返时间越长，通信的效率就越低</font>。如果你说完一句话，我在处理其他事情，没有及时回复你，那你不是要干等着我做完其他事情后，我回复你，你才能说下一句话，很显然这不现实。

那么有了窗口，就可以指定窗口大小，窗口大小就是指**无需等待确认应答，而可以继续发送数据的最大值**。窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。

中途若有 ACK 丢失，可以通过「下一个确认应答进行确认」。如下图：

<img src="http://images.xyzzs.top/image/image-20230131112129019.png_char" alt="image-20230131112129019" style="zoom:80%;" />

图中的 ACK 600 确认应答报文丢失，也没关系，因为可以通过下一个确认应答进行确认，只要发送方收到了 ACK 700 确认应答，就意味着 700 之前的所有数据「接收方」都收到了。这个模式就叫**累计确认**或者**累计应答**。

:question:<font color=red>**窗口大小由哪一方决定？**</font>

TCP 头里有一个字段叫 `Window`，也就是窗口大小。

**这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。**

所以，通常窗口的大小是由接收方的窗口大小来决定的。

发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。



:question:接收窗口和发送窗口的大小是相等的吗？

并不是完全相等，接收窗口的大小是**约等于**发送窗口的大小的。

因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系



<mark>流量控制</mark>

流量控制（flow control）就是让发送方的发送速率不要太快，既要让接收方来得及接收，也不要使网络发生拥塞。<font color=orchid>利用滑动窗口机制</font>可以很方便地在 TCP 连接上实现流量控制。 **TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。**

防止发送方发送速率太快，接收方缓存区不够导致溢出。接收方会维护一个接收窗口 receiver window（窗口大小单位是字节），接受窗口的大小是根据自己的资源情况动态调整的，在返回ACK时将接受窗口大小放在TCP报文中的窗口字段告知发送方。发送窗口的大小不能超过接受窗口的大小，只有当发送方发送并收到确认之后，才能将发送窗口右移。



### 拥塞控制

前面的流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。

**在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大....**



为了在「发送方」调节所要发送数据的量，定义了一个叫做「**拥塞窗口**」的概念。

:question:什么是拥塞窗口？和发送窗口有什么关系呢？

**拥塞窗口 cwnd**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化的**。

我们在前面提到过发送窗口 `swnd` 和接收窗口 `rwnd` 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是<font color=orchid>swnd = min(cwnd, rwnd)</font>，也就是拥塞窗口和接收窗口中的最小值。<font color=orchid>接收窗口表明了接收方的接收能力，拥塞窗口表明了网络的传送能力。</font>

拥塞窗口 `cwnd` 变化的规则：

- 只要网络中没有出现拥塞，`cwnd` 就会增大；
- 但网络中出现了拥塞，`cwnd` 就减少；



:question:那么怎么知道当前网络是否出现了拥塞呢？

其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是**发生了超时重传，就会认为网络出现了拥塞。**



<mark>拥塞控制四个算法</mark>

- <font color=red>慢启动</font>

  TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量。

  <img src="http://images.xyzzs.top/image/image-20230131123744165.png_char" alt="image-20230131123744165" style="zoom: 67%;" />

  可以看出慢启动算法，发包的个数是**指数性的增长**。那慢启动涨到什么时候是个头呢？

  有一个叫<font color=orchid>慢启动门限</font>  `ssthresh` （slow start threshold）状态变量。

  - 当 `cwnd` <  `ssthresh` 时，使用慢启动算法。
  - 当 `cwnd` >= `ssthresh` 时，就会使用「拥塞避免算法」。

- <font color=red>拥塞避免</font>

  当拥塞窗口 `cwnd` 「超过」慢启动门限 `ssthresh` 就会进入拥塞避免算法。

  一般来说 `ssthresh` 的大小是 `65535` 字节。

  <img src="http://images.xyzzs.top/image/image-20230131124101976.png_char_char" alt="image-20230131124101976" style="zoom:67%;" />

  我们可以发现，拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。

  当触发了重传机制，也就进入了「拥塞发生算法」。

- <font color=red>拥塞发生</font>

  当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：

  - 超时重传
  - 快速重传

  这两种使用的拥塞发送算法是不同的，接下来分别来说说。

  >  发生超时重传的拥塞发生算法

  这个时候，ssthresh 和 cwnd 的值会发生变化：

  - `ssthresh` 设为 `cwnd/2`，
  - `cwnd` 重置为 `1` （是恢复为 cwnd 初始化值，我这里假定 cwnd 初始化值 1）

  接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是一旦「超时重传」，马上回到解放前。但是这种方式太激进了，会造成网络卡顿。

  <img src="http://images.xyzzs.top/image/image-20230131125015710.png_char" alt="image-20230131125015710" style="zoom:67%;" />

  >  发生快速重传的拥塞发生算法

  当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。

  TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 `ssthresh` 和 `cwnd` 变化如下：

  - `cwnd = cwnd/2` ，也就是设置为原来的一半;
  - `ssthresh = cwnd`;
  - 进入快速恢复算法

- <font color=red>快速恢复</font>

  快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像超时重传那么极端。

  正如前面所说，进入快速恢复之前，`cwnd` 和 `ssthresh` 已被更新了：

  - `cwnd = cwnd/2` ，也就是设置为原来的一半;
  - `ssthresh = cwnd`;

  然后，进入快速恢复算法如下：

  - 拥塞窗口 `cwnd = ssthresh + 3` （ 3 的意思是确认有 3 个数据包被收到了）；
  - 重传丢失的数据包；
  - 如果再收到重复的 ACK，那么 cwnd 增加 1；
  - 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated  ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；

  也就是没有像「超时重传」一夜回到解放前，而是还在比较高的值，后续呈线性增长。

  <img src="http://images.xyzzs.top/image/image-20230131125746003.png_char_char" style="zoom:80%;" />



### 既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？

<img src="http://images.xyzzs.top/image/image-20230131100943841.png_char" alt="image-20230131100943841" style="zoom:80%;" />

- `MTU`：一个网络包的最大长度，以太网中一般为 `1500` 字节；
- `MSS`：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度；

**那么当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传**。因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。因此，可以得知由 IP 层进行分片传输，是非常没有效率的。

为了达到最佳的传输效能 TCP 协议在**建立连接的时候通常要协商双方的 MSS 值**，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU 。经过 TCP 层分片后，如果一个 TCP 分片丢失后，**进行重发时也是以 MSS 为单位**，而不用重传所有的分片，大大增加了重传的效率。



## 应用层

:question:HTTP是什么？

HTTP 是超文本传输协议，也就是**H**yper**T**ext **T**ransfer **P**rotocol。

- 协议：HTTP 是一个用在计算机世界里的**协议**。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范（**两个以上的参与者**），以及相关的各种控制和错误处理方式（**行为约定和规范**）。
- 传输：HTTP 是一个在计算机世界里专门用来在**两点之间双向传输数据**的约定和规范。
- 超文本：HTTP 传输的内容是「超文本」，是**超越了普通文本的文本**，它是文字、图片、视频等的混合体，最关键有超链接，能从一个超文本跳转到另外一个超文本。HTML 就是最常见的超文本了，它本身只是纯文字文件，但内部用很多标签定义了图片、视频等的链接，再经过浏览器的解释，呈现给我们的就是一个文字、有画面的网页了。

**HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。**



### HTTP 常见的状态码有哪些？

![image-20230130094302258](http://images.xyzzs.top/image/image-20230130094302258.png_char)

1. `1xx` 类状态码属于**提示信息**，是协议处理中的一种中间状态，实际用到的比较少。

   - 「**101」 **协议切换。

2. `2xx` 类状态码表示服务器**成功**处理了客户端的请求，也是我们最愿意看到的状态。

   - 「**200 OK**」是最常见的成功状态码，表示一切正常。如果是非 `HEAD` 请求，服务器返回的响应头都会有 body 数据。

   - 「**204 No Content**」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。
   - 「**206 Partial Content**」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。

3. `3xx` 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是**重定向**。

   - 「**301 Moved Permanently**」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。
   - 「**302 Found**」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。

   301 和 302 都会在响应头里使用字段 `Location`，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。

   - 「**304 Not Modified**」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。

4. `4xx` 类状态码表示客户端发送的**报文有误**，服务器无法处理，也就是错误码的含义。

   - 「**400 Bad Request**」表示客户端请求的报文有错误，但只是个笼统的错误。
   - 「**403 Forbidden**」表示服务器禁止访问资源，并不是客户端的请求出错。
   - 「**404 Not Found**」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。

5. `5xx` 类状态码表示客户端请求报文正确，但是**服务器处理时内部发生了错误**，属于服务器端的错误码。

   - 「**500 Internal Server Error**」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。
   - 「**501 Not Implemented**」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。
   - 「**502 Bad Gateway**」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。
   - 「**503 Service Unavailable**」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思

### HTTP 常见字段有哪些？

- Host ：客户端发送请求时，用来指定服务器的域名。`Host: www.baidu.com`
- Content-Length ： 服务器在返回数据时，会有 `Content-Length` 字段，表明本次回应的数据长度。`Accept-Encoding: gzip, deflate`
- Connection ： 最常用于客户端要求服务器使用「HTTP 长连接」机制，以便其他请求复用。`Connection: Keep-Alive`
- Content-Type :  用于服务器回应时，告诉客户端，本次数据是什么格式。`Content-Type: text/html; Charset=utf-8`
- Accept : 客户端请求的时候，可以使用 `Accept` 字段声明自己可以接受哪些数据格式。`Accept: */*`
- Content-Encoding ： 字段说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式。`Content-Encoding: gzip`
- Accept-Encoding ：客户端在请求时，用 `Accept-Encoding` 字段说明自己可以接受哪些压缩方法。`Accept-Encoding: gzip, deflate`

### HTTP 缓存技术

:question:HTTP 缓存有哪些实现方式？

对于一些具有重复性的 HTTP 请求，比如每次请求得到的数据都一样的，我们可以把这对「请求-响应」的数据都**缓存在本地**，那么下次就直接读取本地的数据，不必在通过网络获取服务器的响应了。HTTP 缓存有两种实现方式，分别是**强制缓存和协商缓存**。

<mark>强制缓存</mark>

强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。

如下图中，返回的是 200 状态码，但在 size 项中标识的是 from disk cache，就是使用了强制缓存。

<img src="http://images.xyzzs.top/image/image-20230130100617089.png_char" alt="image-20230130100617089" style="zoom: 33%;" />

<mark>协商缓存</mark>

当我们在浏览器使用开发者工具的时候，你可能会看到过某些请求的响应码是 `304`，这个是告诉浏览器可以使用本地缓存的资源，通常这种通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存。**协商缓存就是与服务端协商之后，通过协商结果来判断是否使用<font color=orchid>本地过期缓存</font>**。

<img src="http://images.xyzzs.top/image/image-20230130101053480.png_char" alt="image-20230130101053480" style="zoom:67%;" />



### HTTP 与 HTTPS

### HTTP 与 HTTPS 有哪些区别？

- HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
- 两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。
- HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

![image-20230130102521258](http://images.xyzzs.top/image/image-20230130102521258.png_char)

<mark>HTTPS 解决了 HTTP 的哪些问题？</mark>

HTTP 由于是明文传输，所以安全上存在以下三个风险：

- **窃听风险**，比如通信链路上可以获取通信内容，用户号容易没。
- **篡改风险**，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。
- **冒充风险**，比如冒充淘宝网站，用户钱容易没

HTTPS 是如何解决上面的三个风险的？

- **信息加密**：**混合加密**的方式实现信息的**机密性**，解决了窃听的风险。
- **校验机制**：**摘要算法**的方式来实现**完整性**，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。
- **身份证书**：将服务器公钥放入到**数字证书**中，解决了冒充的风险。



### 谈谈网络传输安全

:question:为什么采用<font color=orchid>混合加密</font>？

- **对称加密**只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。
- **非对称加密**使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。

一般我们不会用非对称加密来加密实际的传输内容，因为非对称加密的计算比较耗费性能的。



:question:如何保证数据未被篡改？

1. <font color=orchid>摘要算法</font>——保证消息的完整性

为了保证传输的内容不被篡改，我们需要对内容计算出一个「指纹」，然后同内容一起传输给对方。

**用摘要算法（哈希函数）来计算出内容的哈希值**，也就是内容的「指纹」，这个**哈希值是唯一的，且无法通过哈希值推导出内容**。

将内容和指纹一起发送，对方收到后，先是对内容也计算出一个「指纹」，然后跟发送方发送的「指纹」做一个比较，如果「指纹」相同，说明内容没有被篡改，否则就可以判断出内容被篡改了。

通过哈希算法可以确保内容不会被篡改，<font color=orchid>但是并不能保证「内容 + 哈希值」不会被中间人替换，因为这里缺少对客户端收到的消息是否来源于服务端的证明</font>。那么请看数字签名吧。

2. <font color=orchid>数字签名</font>——保证消息的来源可靠性

非对称加密算法，共有两个密钥：

- 一个是公钥，这个是可以公开给所有人的；
- 一个是私钥，这个必须由本人管理，不可泄露。

这两个密钥可以**双向加解密**的，比如可以用公钥加密内容，然后用私钥解密，也可以用私钥加密内容，公钥解密内容。

流程的不同，意味着目的也不相同：

- **公钥加密，私钥解密**。这个目的是为了**保证内容传输的安全**，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容；
- **私钥加密，公钥解密**。这个目的是为了**保证消息不会被冒充**，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。

所以非对称加密的用途主要在于**通过「私钥加密，公钥解密」的方式，来确认消息的身份**，我们常说的**数字签名算法**，就是用的是这种方式，不过私钥加密内容不是内容本身，而是**对内容的哈希值加密**。



<font color=orchid>数字证书</font>——身份验证

前面我们知道：

- 可以通过哈希算法来保证消息的完整性；
- 可以通过数字签名来保证消息的来源可靠性（能确认消息是由持有私钥的一方发送的）；

但是这还远远不够，**还缺少身份验证的环节**，万一公钥是被伪造的呢？

在网络传输过程中，只要截获发送方 A 发出的内容，就可以伪造一个公私钥发给接收方 B，实现与接收方B数据交互。

既然伪造公私钥那么随意，所以要把 A 的公钥注册到**数字证书认证机构**，数字证书认证机构用他们自己的私钥对 A 的公钥做了个数字签名，然后把 A 的<font color=orchid>个人信息 + 公钥 + 数字签名</font>打包成一个**数字证书，也就是说这个数字证书包含A的公钥。**

这样，A需要发送内容的时候，不仅会用A自己的私钥对内容进行签名，<font color=orchid>还会把数字证书给到接收方B</font>。

接收方B拿到了数字证书后，<font color=orchid>首先会去数字证书认证机构验证这个数字证书是否合法</font>，因为数字证书里有数字证书认证机构的数字签名，数字证书认证机构要验证证书合法性的时候，用自己的公钥解密，如果能解密成功，就说明这个数字证书是在数字证书认证机构注册过的，就认为该数字证书是合法的，然后就会<font color=orchid>把数字证书里头的公钥（发送方A的）给到接收方B</font>。

**由于通过数字证书认证机构验证了数字证书是合法的，那么就能证明这个公钥就是发送方的**，于是接收方B就可以安心的用这个公钥解密，如果能解密出，就证明确实是发送方A发出的。

正是通过了一个权威的机构来证明发送方A的身份，所以伪造公私钥这个小伎俩就没用了。

在计算机里，这个权威的机构就是 CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。![image-20230130110229495](http://images.xyzzs.top/image/image-20230130110229495.png_char_char)



### 既然有 HTTP 协议，为什么还要有 RPC？

现在电脑上装的各种**联网**软件，比如 xx管家，xx卫士，它们都作为客户端（Client）需要跟服务端（Server）建立连接收发消息，此时都会用到应用层协议，在这种 Client/Server (C/S) 架构下，它们可以使用自家造的 RPC 协议，因为它只管连自己公司的服务器就 ok 了。

但有个软件不同，**浏览器（Browser）**，不管是 Chrome 还是 IE，它们不仅要能访问自家公司的服务器（Server），还需要访问其他公司的网站服务器，因此它们需要有个统一的标准，不然大家没法交流。于是，HTTP 就是那个时代用于统一 Browser/Server (B/S) 的协议。

也就是说在多年以前，**HTTP 主要用于 B/S 架构，而 RPC 更多用于 C/S 架构**。但现在其实已经没分那么清了，B/S 和 C/S 在慢慢融合。很多软件同时支持多端，比如某度云盘，既要支持网页版，还要支持手机端和 PC 端，如果通信协议都用 HTTP 的话，那服务器只用同一套就够了。而 RPC 就开始退居幕后，一般用于公司内部集群里，各个微服务之间的通讯。

那这么说的话，都用 HTTP 得了，还用什么 RPC？那这就要从它们之间的区别开始说起。

:question:HTTP 和 RPC 有什么区别

- 传输的内容

  HTTP里面的内容非常多的**冗余**，显得**非常啰嗦**。最明显的，像 `Header` 里的那些信息，其实如果我们约定好头部的第几位是 `Content-Type`，就**不需要每次都真的把`Content-Type`这个字段都传过来**，类似的情况其实在 `body` 的 Json 结构里也特别明显。

  而 RPC，因为它定制化程度更高，可以采用体积更小的 Protobuf 或其他序列化协议去保存结构体数据，同时也不需要像 HTTP 那样考虑各种浏览器行为。**因此性能也会更好一些，这也是在公司内部微服务中抛弃 HTTP，选择使用 RPC 的最主要原因。**

- 服务发现

- 底层连接形式



当然上面说的 HTTP，其实**特指的是现在主流使用的 HTTP/1.1**，`HTTP/2` 在前者的基础上做了很多改进，所以**性能可能比很多 RPC 协议还要好**，甚至连 `gRPC` 底层都直接用的 `HTTP/2`

<mark>小结</mark>

- 纯裸 TCP 是能收发数据，但它是个**无边界**的数据流，上层需要定义消息格式用于定义**消息边界**。于是就有了各种协议，HTTP 和各类 RPC 协议就是在 TCP 之上定义的应用层协议。
- **RPC 本质上不算是协议，而是一种调用方式**，而像 gRPC 和 Thrift 这样的具体实现，才是协议，它们是实现了 RPC 调用的协议。目的是希望程序员能像调用本地方法那样去调用远端的服务方法。同时 RPC 有很多种实现方式，**不一定非得基于 TCP 协议**。
- 从发展历史来说，**HTTP 主要用于 B/S 架构，而 RPC 更多用于 C/S 架构。但现在其实已经没分那么清了，B/S 和 C/S 在慢慢融合**。很多软件同时支持多端，所以对外一般用 HTTP 协议，而内部集群的微服务之间则采用 RPC 协议进行通讯。
- RPC 其实比 HTTP 出现的要早，且比目前主流的 HTTP/1.1 **性能**要更好，所以大部分公司内部都还在使用 RPC。
- **HTTP/2.0** 在 **HTTP/1.1** 的基础上做了优化，性能可能比很多 RPC 协议都要好，但由于是这几年才出来的，所以也不太可能取代掉 RPC。



### 既然有 HTTP 协议，为什么还要有 WebSocket？

平时我们打开网页，比如购物网站某宝。都是点一下「列表商品」，跳转一下网页就到了「商品详情」。

从 HTTP 协议的角度来看，就是点一下网页上的某个按钮，**前端发一次 HTTP请 求，网站返回一次 HTTP 响应**。这种由客户端主动请求，服务器响应的方式也满足大部分网页的功能场景。但有没有发现，这种情况下，服务器从来就「不会主动」给客户端发一次消息。

这时候，你打开一个网页游戏，上来就是一个小怪，从远处走来，然后疯狂拿木棒子抽你。

**你全程没点任何一次鼠标**。服务器就自动将怪物的移动数据和攻击数据源源不断发给你了。



像这种**看起来服务器主动发消息给客户端的场景**，是怎么做到的？

在真正回答这个问题之前，我们先来聊下一些相关的知识背景。

<font color=orchid>1、使用 HTTP 不断轮询</font>

其实问题的痛点在于，**怎么样才能在用户不做任何操作的情况下，网页能收到消息并发生变更。**

最常见的解决方案是，**网页的前端代码里不断定时发 HTTP 请求到服务器，服务器收到请求后给客户端响应消息。**这其实时一种「**伪**」服务器推的形式。

用这种方式的场景也有很多，最常见的就是**扫码登录**。

比如，某信公众号平台，登录页面二维码出现之后，**前端**网页根本不知道用户扫没扫，于是不断去向**后端**服务器询问，看有没有人扫过这个码。而且是以大概 1 到 2 秒的间隔去不断发出请求，这样可以保证用户在扫码后能在 1 到 2 秒内得到及时的反馈，不至于**等太久**。

但这样，会有两个比较明显的问题：1 消耗带宽；2 明显的卡顿

<font color=orchid>2、长轮询</font>

我们知道，HTTP 请求发出后，一般会给服务器留一定的时间做响应，比如 3 秒，规定时间内没返回，就认为是超时。

如果我们的 HTTP 请求**将超时设置的很大**，比如 30 秒，**在这 30 秒内只要服务器收到了扫码请求，就立马返回给客户端网页。如果超时，那就立马发起下一次请求。**这样就减少了 HTTP 请求的个数，并且由于大部分情况下，用户都会在某个 30 秒的区间内做扫码操作，所以响应也是及时的。

<img src="http://images.xyzzs.top/image/image-20230130132125303.png_char" alt="image-20230130132125303" style="zoom: 67%;" />

上面提到的两种解决方案（不断轮询和长轮询），本质上，其实还是客户端主动去取数据。

对于像扫码登录这样的简单场景还能用用。但如果是网页游戏呢，游戏一般会有大量的数据需要从服务器主动推送到客户端。

这就得说下 WebSocket 了。

<mark>WebSocket是什么</mark>

我们知道 TCP 连接的两端，**同一时间里**，**双方**都可以**主动**向对方发送数据。这就是所谓的**全双工**。

而现在使用最广泛的`HTTP/1.1`，也是基于TCP协议的，**同一时间里**，客户端和服务器**只能有一方主动**发数据，这就是所谓的**半双工**。

也就是说，好好的全双工 TCP，被 HTTP/1.1 用成了半双工。

为什么？

这是由于 HTTP 协议设计之初，考虑的是看看网页文本的场景，能做到**客户端发起请求再由服务器响应**，就够了，根本就没考虑网页游戏这种，客户端和服务器之间都要互相主动发大量数据的场景。

所以，为了更好的支持这样的场景，我们需要另外一个**基于TCP的新协议**。

于是新的应用层协议**WebSocket**就被设计出来了。

>  大家别被这个名字给带偏了。虽然名字带了个socket，但其实 **socket 和 WebSocket 之间，就跟雷峰和雷峰塔一样，二者接近毫无关系**。



<mark>怎么建立WebSocket连接</mark>

我们平时刷网页，一般都是在浏览器上刷的，一会刷刷图文，这时候用的是 **HTTP 协议**，一会打开网页游戏，这时候就得切换成我们新介绍的 **WebSocket 协议**。

为了兼容这些使用场景。浏览器在 **TCP 三次握手建立连接之后，都统一使用 HTTP 协议先进行一次通信**。

- 如果此时是**普通的 HTTP 请求**，那后续双方就还是老样子继续用普通 HTTP 协议进行交互。

- 如果这时候是**想建立 WebSocket 连接**，就会在 HTTP 请求里带上一些**特殊的header 头**

  ```http
  Connection: Upgrade
  Upgrade: WebSocket
  Sec-WebSocket-Key: T2a6wZlAwhgQNqruZ2YUyg==\r\n
  ```

  这些 header 头的意思是，浏览器想**升级协议（Connection: Upgrade）**，并且**想升级成 WebSocket 协议（Upgrade: WebSocket）**。同时带上一段**随机生成的 base64 码（Sec-WebSocket-Key）**，发给服务器。

  如果服务器正好支持升级成 WebSocket 协议。就会走 WebSocket 握手流程，同时根据客户端生成的 base64 码，用某个**公开的**算法变成另一段字符串，放在 HTTP 响应的 `Sec-WebSocket-Accept` 头里，同时带上`101状态码`，发回给浏览器。HTTP 的响应如下：

  ```http
  HTTP/1.1 101 Switching Protocols\r\n
  Sec-WebSocket-Accept: iBJKv/ALIW2DobfoA4dmr3JHBCY=\r\n
  Upgrade: WebSocket\r\n
  Connection: Upgrade\r\n
  ```

  <img src="http://images.xyzzs.top/image/image-20230130133331083.png_char" alt="image-20230130133331083" style="zoom:50%;" />

<mark>WebSocket的消息格式</mark>

![image-20230130155035464](http://images.xyzzs.top/image/image-20230130155035464.png_char)

**opcode字段**：这个是用来标志这是个**什么类型**的数据帧。比如。

- 等于 1 ，是指text类型（`string`）的数据包
- 等于 2 ，是二进制数据类型（`[]byte`）的数据包
- 等于 8 ，是关闭连接的信号

**payload字段**：存放的是我们**真正想要传输的数据的长度**，单位是**字节**。

另外，可以看到，我们存放** payload 长度的字段有好几个**，我们既可以用最前面的`7bit`, 也可以用后面的`7+16bit 或 7+64bit。`

- 如果`最开始的7bit`的值是 0~125，那么它就表示了 **payload 全部长度**，只读最开始的`7个bit`就完事了。
- 如果是`126（0x7E）`。那它表示payload的长度范围在 `126~65535` 之间，接下来还需要**再读16bit**。这16bit会包含payload的真实长度。
- 如果是`127（0x7F）`。那它表示payload的长度范围`>=65536`，接下来还需要**再读64bit**。这64bit会包含payload的长度。这能放2的64次方byte的数据，换算一下好多个TB，肯定够用了。

**payload data字段**：这里存放的就是真正要传输的数据，在知道了上面的payload长度后，就可以根据这个值去截取对应的数据。

<mark>WebSocket的使用场景</mark>

WebSocket完美继承了 TCP 协议的**全双工**能力，并且还贴心的提供了解决粘包的方案。

它适用于**需要服务器和客户端（浏览器）频繁交互**的大部分场景，比如网页/小程序游戏，网页聊天室，以及一些类似飞书这样的网页协同办公软件。

回到文章开头的问题，在使用 WebSocket 协议的网页游戏里，怪物移动以及攻击玩家的行为是**服务器逻辑**产生的，对玩家产生的伤害等数据，都需要由**服务器主动发送给客户端**，客户端获得数据后展示对应的效果。

<mark>小结</mark>

- TCP 协议本身是**全双工**的，但我们最常用的 HTTP/1.1，虽然是基于 TCP 的协议，但它是**半双工**的，对于大部分需要服务器主动推送数据到客户端的场景，都不太友好，因此我们需要使用支持全双工的 WebSocket 协议。
- 在 HTTP/1.1 里，只要客户端不问，服务端就不答。基于这样的特点，对于登录页面这样的简单场景，可以使用**定时轮询或者长轮询**的方式实现**服务器推送**(comet)的效果。
- 对于客户端和服务端之间需要频繁交互的复杂场景，比如网页游戏，都可以考虑使用 WebSocket 协议。
- WebSocket 和 socket 几乎没有任何关系，只是叫法相似。
- 正因为各个浏览器都支持 HTTP协 议，所以 WebSocket 会先利用HTTP协议加上一些特殊的 header 头进行握手升级操作，升级成功后就跟 HTTP 没有任何关系了，之后就用 WebSocket 的数据格式进行收发数据。

<!-- https://xiaolincoding.com/network/ -->